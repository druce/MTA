{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A data stack-in-a-box to analyze MTA data with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table - % drop during pandemic, % recovered since pandemic, % from pre pandemic\n",
    "# do cbd\n",
    "# do weekday mornings\n",
    "\n",
    "# make sure first week of 2019 loaded\n",
    "# drop rows where year < 2019\n",
    "# try to do weekday morning in superset\n",
    "# try to do table, big stations\n",
    "# try to do table stations with biggest change 2022 vs 2019\n",
    "# load stations and tag as manhattan below 63\n",
    "# link coords and try to do a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas               1.5.3               \n",
      "seaborn              0.12.2              \n",
      "matplotlib           3.6.3               \n",
      "requests             2.28.2              \n",
      "sqlalchemy           1.4.46              \n",
      "duckdb               0.6.1               \n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "from time import strftime\n",
    "from os import listdir, system\n",
    "import pickle\n",
    "import requests\n",
    "from pathlib import Path\n",
    " \n",
    "import pandas as pd\n",
    "# modin uses multithreading but doesn't play well with sql magic\n",
    "# import modin.pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "import duckdb\n",
    "\n",
    "# Import ipython-sql Jupyter extension to create SQL cells\n",
    "%load_ext sql\n",
    "# directly output data to Pandas and to simplify the output that is printed to the notebook.\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "pd.options.display.max_rows=100\n",
    "\n",
    "# Connect ipython-sql to DuckDB using a SQLAlchemy-style connection string. You may either connect to an in memory DuckDB, or a file backed db.\n",
    "%sql duckdb:///mta.db\n",
    "\n",
    "# import qgrid\n",
    "# from qgrid import show_grid\n",
    "\n",
    "print(f\"pandas               {pd.__version__:<20}\")\n",
    "print(f\"seaborn              {sns.__version__:<20}\")\n",
    "print(f\"matplotlib           {matplotlib.__version__:<20}\")\n",
    "# print(f\"qgrid                {qgrid.__version__:<20}\")\n",
    "print(f\"requests             {requests.__version__:<20}\")\n",
    "print(f\"sqlalchemy           {sqlalchemy.__version__:<20}\")\n",
    "print(f\"duckdb               {duckdb.__version__:<20}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data overview](https://data.ny.gov/api/views/py8k-a8wg/files/535bc30e-4119-4992-a799-65d1a05849d4?download=true&filename=MTA_Turnstile_Data_Overview.pdf)\n",
    "- [Data dictionary](https://data.ny.gov/api/views/py8k-a8wg/files/5c602688-3031-4f39-8f2b-d4a3cd8c3752?download=true&filename=MTA_Turnstile_Data_DataDictionary.pdf)\n",
    "- [List of stations](http://web.mta.info/developers/data/nyct/subway/Stations.csv)\n",
    "- [Alt station list](https://data.cityofnewyork.us/api/views/kk4q-3rt2/rows.csv)\n",
    "- [Things to watch out for while working with the MTA turnstile data in 2022](https://towardsai.net/p/l/things-to-watch-out-for-while-working-with-the-mta-turnstile-data-in-2022#:~:text=Additionally%2C%20there%20may%20be%20a,missed%20audit%20that%20was%20recovered.)\n",
    "- [Taming the MTA's unruly turnstile data](https://medium.com/qri-io/taming-the-mtas-unruly-turnstile-data-c945f5f96ba0)\n",
    "- [State Comptroller dashboard](https://www.osc.state.ny.us/reports/osdc/impact-covid-19-pandemic-subway-ridership-new-york-city)\n",
    "- [Todd Schneider repo](https://github.com/toddwschneider/nyc-subway-turnstile-data)\n",
    "- [Sonny Ng project](https://www.subwayridership.nyc/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch raw data files\n",
    "# for any missing saturday after start_date and before today\n",
    "    \n",
    "downloaddir = \"downloads\"\n",
    "csvdir = \"csv\"\n",
    "prefix = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_\"\n",
    "suffix = \".txt\"\n",
    "start_date = date(2019, 1, 7) # start with 1st full week of 2019\n",
    "end_date = date.today()\n",
    "delta = end_date - start_date   # returns timedelta\n",
    "\n",
    "alldays = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "alldays = [day for day in alldays if day.weekday() == 5]\n",
    "\n",
    "for d in alldays:\n",
    "    inix=strftime(\"%y%m%d\", d.timetuple())\n",
    "    url = \"%s%s%s\" % (prefix, inix, suffix)\n",
    "    src = \"%s/%s%s\" % (downloaddir, inix, suffix)\n",
    "    \n",
    "    if Path(src).is_file():\n",
    "        continue\n",
    "    \n",
    "    cmd = \"curl %s > %s\" % (url, src)\n",
    "    print(cmd)\n",
    "    system(cmd)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "['downloads/190105.txt', 'downloads/190112.txt', 'downloads/190119.txt']\n",
      "['downloads/221231.txt', 'downloads/230107.txt', 'downloads/230114.txt']\n"
     ]
    }
   ],
   "source": [
    "datadir = \"downloads\"\n",
    "datafiles = sorted([\"downloads/\" + f for f in listdir(datadir) if f[-4:]==\".txt\"])\n",
    "print(len(datafiles))\n",
    "print(datafiles[:3])\n",
    "print(datafiles[-3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    201604 downloads/190105.txt\n",
      "    201091 downloads/190112.txt\n",
      "    204728 downloads/190119.txt\n",
      "    201600 downloads/190126.txt\n",
      "    202913 downloads/190202.txt\n",
      "    202736 downloads/190209.txt\n",
      "    204738 downloads/190216.txt\n",
      "    204056 downloads/190223.txt\n",
      "    203190 downloads/190302.txt\n",
      "    203988 downloads/190309.txt\n",
      "    201793 downloads/190316.txt\n",
      "    202723 downloads/190323.txt\n",
      "    204596 downloads/190330.txt\n",
      "    202965 downloads/190406.txt\n",
      "    204712 downloads/190413.txt\n",
      "    202548 downloads/190420.txt\n",
      "    203858 downloads/190427.txt\n",
      "    206858 downloads/190504.txt\n",
      "    204089 downloads/190511.txt\n",
      "    208682 downloads/190518.txt\n",
      "    203364 downloads/190525.txt\n",
      "    203796 downloads/190601.txt\n",
      "    205012 downloads/190608.txt\n",
      "    204935 downloads/190615.txt\n",
      "    207478 downloads/190622.txt\n",
      "    205964 downloads/190629.txt\n",
      "    209539 downloads/190706.txt\n",
      "    208798 downloads/190713.txt\n",
      "    209007 downloads/190720.txt\n",
      "    206531 downloads/190727.txt\n",
      "    206997 downloads/190803.txt\n",
      "    205876 downloads/190810.txt\n",
      "    208567 downloads/190817.txt\n",
      "    205670 downloads/190824.txt\n",
      "    205264 downloads/190831.txt\n",
      "    204796 downloads/190907.txt\n",
      "    205586 downloads/190914.txt\n",
      "    204929 downloads/190921.txt\n",
      "    205337 downloads/190928.txt\n",
      "    206604 downloads/191005.txt\n",
      "    206860 downloads/191012.txt\n",
      "    206820 downloads/191019.txt\n",
      "    205596 downloads/191026.txt\n",
      "    206047 downloads/191102.txt\n",
      "    207617 downloads/191109.txt\n",
      "    204984 downloads/191116.txt\n",
      "    205533 downloads/191123.txt\n",
      "    205545 downloads/191130.txt\n",
      "    205925 downloads/191207.txt\n",
      "    205188 downloads/191214.txt\n",
      "    207606 downloads/191221.txt\n",
      "    206708 downloads/191228.txt\n",
      "    206500 downloads/200104.txt\n",
      "    206074 downloads/200111.txt\n",
      "    205622 downloads/200118.txt\n",
      "    205102 downloads/200125.txt\n",
      "    205142 downloads/200201.txt\n",
      "    205921 downloads/200208.txt\n",
      "    205730 downloads/200215.txt\n",
      "    206184 downloads/200222.txt\n",
      "    207018 downloads/200229.txt\n",
      "    207884 downloads/200307.txt\n",
      "    203966 downloads/200314.txt\n",
      "    206746 downloads/200321.txt\n",
      "    205763 downloads/200328.txt\n",
      "    205667 downloads/200404.txt\n",
      "    205982 downloads/200411.txt\n",
      "    206177 downloads/200418.txt\n",
      "    206363 downloads/200425.txt\n",
      "    206903 downloads/200502.txt\n",
      "    206174 downloads/200509.txt\n",
      "    206906 downloads/200516.txt\n",
      "    206593 downloads/200523.txt\n",
      "    210415 downloads/200530.txt\n",
      "    207893 downloads/200606.txt\n",
      "    206663 downloads/200613.txt\n",
      "    206740 downloads/200620.txt\n",
      "    206672 downloads/200627.txt\n",
      "    208881 downloads/200704.txt\n",
      "    206349 downloads/200711.txt\n",
      "    206263 downloads/200718.txt\n",
      "    206985 downloads/200725.txt\n",
      "    206705 downloads/200801.txt\n",
      "    207113 downloads/200808.txt\n",
      "    206782 downloads/200815.txt\n",
      "    209762 downloads/200822.txt\n",
      "    217833 downloads/200829.txt\n",
      "    208052 downloads/200905.txt\n",
      "    210586 downloads/200912.txt\n",
      "    209662 downloads/200919.txt\n",
      "    209831 downloads/200926.txt\n",
      "    212159 downloads/201003.txt\n",
      "    210221 downloads/201010.txt\n",
      "    207668 downloads/201017.txt\n",
      "    211325 downloads/201024.txt\n",
      "    211985 downloads/201031.txt\n",
      "    213106 downloads/201107.txt\n",
      "    208777 downloads/201114.txt\n",
      "    210258 downloads/201121.txt\n",
      "    209779 downloads/201128.txt\n",
      "    209781 downloads/201205.txt\n",
      "    210404 downloads/201212.txt\n",
      "    210923 downloads/201219.txt\n",
      "    212300 downloads/201226.txt\n",
      "    210434 downloads/210102.txt\n",
      "    210167 downloads/210109.txt\n",
      "    209882 downloads/210116.txt\n",
      "    208846 downloads/210123.txt\n",
      "    208916 downloads/210130.txt\n",
      "    209080 downloads/210206.txt\n",
      "    208622 downloads/210213.txt\n",
      "    209045 downloads/210220.txt\n",
      "    209928 downloads/210227.txt\n",
      "    209076 downloads/210306.txt\n",
      "    209318 downloads/210313.txt\n",
      "    207055 downloads/210320.txt\n",
      "    209471 downloads/210327.txt\n",
      "    209069 downloads/210403.txt\n",
      "    209567 downloads/210410.txt\n",
      "    209692 downloads/210417.txt\n",
      "    209106 downloads/210424.txt\n",
      "    208971 downloads/210501.txt\n",
      "    209176 downloads/210508.txt\n",
      "    209040 downloads/210515.txt\n",
      "    209316 downloads/210522.txt\n",
      "    208913 downloads/210529.txt\n",
      "    209532 downloads/210605.txt\n",
      "    209507 downloads/210612.txt\n",
      "    209261 downloads/210619.txt\n",
      "    209412 downloads/210626.txt\n",
      "    209831 downloads/210703.txt\n",
      "    209689 downloads/210710.txt\n",
      "    209294 downloads/210717.txt\n",
      "    209400 downloads/210724.txt\n",
      "    209464 downloads/210731.txt\n",
      "    209503 downloads/210807.txt\n",
      "    209245 downloads/210814.txt\n",
      "    209416 downloads/210821.txt\n",
      "    209069 downloads/210828.txt\n",
      "    209736 downloads/210904.txt\n",
      "    209484 downloads/210911.txt\n",
      "    209899 downloads/210918.txt\n",
      "    210401 downloads/210925.txt\n",
      "    210212 downloads/211002.txt\n",
      "    209768 downloads/211009.txt\n",
      "    209998 downloads/211016.txt\n",
      "    209985 downloads/211023.txt\n",
      "    209885 downloads/211030.txt\n",
      "    209229 downloads/211106.txt\n",
      "    212174 downloads/211113.txt\n",
      "    209973 downloads/211120.txt\n",
      "    210190 downloads/211127.txt\n",
      "    210235 downloads/211204.txt\n",
      "    210442 downloads/211211.txt\n",
      "    210141 downloads/211218.txt\n",
      "    210384 downloads/211225.txt\n",
      "    210332 downloads/220101.txt\n",
      "    209630 downloads/220108.txt\n",
      "    209791 downloads/220115.txt\n",
      "    209863 downloads/220122.txt\n",
      "    209648 downloads/220129.txt\n",
      "    210084 downloads/220205.txt\n",
      "    210005 downloads/220212.txt\n",
      "    210619 downloads/220219.txt\n",
      "    209850 downloads/220226.txt\n",
      "    209780 downloads/220305.txt\n",
      "    210239 downloads/220312.txt\n",
      "    207557 downloads/220319.txt\n",
      "    211136 downloads/220326.txt\n",
      "    211020 downloads/220402.txt\n",
      "    211303 downloads/220409.txt\n",
      "    212036 downloads/220416.txt\n",
      "    211087 downloads/220423.txt\n",
      "    211267 downloads/220430.txt\n",
      "    211174 downloads/220507.txt\n",
      "    211017 downloads/220514.txt\n",
      "    210476 downloads/220521.txt\n",
      "    211708 downloads/220528.txt\n",
      "    211610 downloads/220604.txt\n",
      "    211248 downloads/220611.txt\n",
      "    211154 downloads/220618.txt\n",
      "    212413 downloads/220625.txt\n",
      "    211264 downloads/220702.txt\n",
      "    210933 downloads/220709.txt\n",
      "    210933 downloads/220716.txt\n",
      "    210230 downloads/220723.txt\n",
      "    210656 downloads/220730.txt\n",
      "    210959 downloads/220806.txt\n",
      "    211950 downloads/220813.txt\n",
      "    210600 downloads/220820.txt\n",
      "    211048 downloads/220827.txt\n",
      "    212449 downloads/220903.txt\n",
      "    212391 downloads/220910.txt\n",
      "    210699 downloads/220917.txt\n",
      "    210592 downloads/220924.txt\n",
      "    211382 downloads/221001.txt\n",
      "    211004 downloads/221008.txt\n",
      "    210700 downloads/221015.txt\n",
      "    211038 downloads/221022.txt\n",
      "    211473 downloads/221029.txt\n",
      "    211162 downloads/221105.txt\n",
      "    213602 downloads/221112.txt\n",
      "    210826 downloads/221119.txt\n",
      "    209936 downloads/221126.txt\n",
      "    211481 downloads/221203.txt\n",
      "    209987 downloads/221210.txt\n",
      "    210186 downloads/221217.txt\n",
      "    209995 downloads/221224.txt\n",
      "    209751 downloads/221231.txt\n",
      "    210781 downloads/230107.txt\n",
      "    212825 downloads/230114.txt\n",
      "  43986566 total\n"
     ]
    }
   ],
   "source": [
    "# count the lines\n",
    "!wc -l downloads/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest & initial cleanup with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:57:17 Starting DuckDB initial load\n"
     ]
    }
   ],
   "source": [
    "# load into mta.db\n",
    "print (\"%s Starting DuckDB initial load\" % (strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists mta;\n",
    "drop table if exists temp_data;\n",
    "\n",
    "create table temp_data(\n",
    "    \"C/A\" VARCHAR, \n",
    "    UNIT VARCHAR, \n",
    "    SCP VARCHAR, \n",
    "    STATION VARCHAR, \n",
    "    LINENAME VARCHAR, \n",
    "    DIVISION VARCHAR, \n",
    "    DATE DATE, \n",
    "    TIME TIME, \n",
    "    \"DESC\" VARCHAR, \n",
    "    ENTRY_COUNTER INTEGER, \n",
    "    EXIT_COUNTER INTEGER);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:57:18 Loading downloads/190105.txt\n",
      "22:57:21 Loading downloads/190112.txt\n",
      "22:57:23 Loading downloads/190119.txt\n",
      "22:57:25 Loading downloads/190126.txt\n",
      "22:57:27 Loading downloads/190202.txt\n",
      "22:57:29 Loading downloads/190209.txt\n",
      "22:57:31 Loading downloads/190216.txt\n",
      "22:57:33 Loading downloads/190223.txt\n",
      "22:57:35 Loading downloads/190302.txt\n",
      "22:57:36 Loading downloads/190309.txt\n",
      "22:57:40 Loading downloads/190316.txt\n",
      "22:57:42 Loading downloads/190323.txt\n",
      "22:57:44 Loading downloads/190330.txt\n",
      "22:57:45 Loading downloads/190406.txt\n",
      "22:57:47 Loading downloads/190413.txt\n",
      "22:57:49 Loading downloads/190420.txt\n",
      "22:57:50 Loading downloads/190427.txt\n",
      "22:57:52 Loading downloads/190504.txt\n",
      "22:57:54 Loading downloads/190511.txt\n",
      "22:57:56 Loading downloads/190518.txt\n",
      "22:57:58 Loading downloads/190525.txt\n",
      "22:58:00 Loading downloads/190601.txt\n",
      "22:58:01 Loading downloads/190608.txt\n",
      "22:58:03 Loading downloads/190615.txt\n",
      "22:58:04 Loading downloads/190622.txt\n",
      "22:58:06 Loading downloads/190629.txt\n",
      "22:58:08 Loading downloads/190706.txt\n",
      "22:58:09 Loading downloads/190713.txt\n",
      "22:58:11 Loading downloads/190720.txt\n",
      "22:58:12 Loading downloads/190727.txt\n",
      "22:58:14 Loading downloads/190803.txt\n",
      "22:58:15 Loading downloads/190810.txt\n",
      "22:58:17 Loading downloads/190817.txt\n",
      "22:58:18 Loading downloads/190824.txt\n",
      "22:58:19 Loading downloads/190831.txt\n",
      "22:58:21 Loading downloads/190907.txt\n",
      "22:58:22 Loading downloads/190914.txt\n",
      "22:58:23 Loading downloads/190921.txt\n",
      "22:58:24 Loading downloads/190928.txt\n",
      "22:58:25 Loading downloads/191005.txt\n",
      "22:58:27 Loading downloads/191012.txt\n",
      "22:58:28 Loading downloads/191019.txt\n",
      "22:58:29 Loading downloads/191026.txt\n",
      "22:58:30 Loading downloads/191102.txt\n",
      "22:58:32 Loading downloads/191109.txt\n",
      "22:58:33 Loading downloads/191116.txt\n",
      "22:58:34 Loading downloads/191123.txt\n",
      "22:58:35 Loading downloads/191130.txt\n",
      "22:58:36 Loading downloads/191207.txt\n",
      "22:58:37 Loading downloads/191214.txt\n",
      "22:58:39 Loading downloads/191221.txt\n",
      "22:58:40 Loading downloads/191228.txt\n",
      "22:58:41 Loading downloads/200104.txt\n",
      "22:58:42 Loading downloads/200111.txt\n",
      "22:58:43 Loading downloads/200118.txt\n",
      "22:58:45 Loading downloads/200125.txt\n",
      "22:58:46 Loading downloads/200201.txt\n",
      "22:58:47 Loading downloads/200208.txt\n",
      "22:58:48 Loading downloads/200215.txt\n",
      "22:58:49 Loading downloads/200222.txt\n",
      "22:58:51 Loading downloads/200229.txt\n",
      "22:58:52 Loading downloads/200307.txt\n",
      "22:58:53 Loading downloads/200314.txt\n",
      "22:58:54 Loading downloads/200321.txt\n",
      "22:58:55 Loading downloads/200328.txt\n",
      "22:58:56 Loading downloads/200404.txt\n",
      "22:58:58 Loading downloads/200411.txt\n",
      "22:58:59 Loading downloads/200418.txt\n",
      "22:59:00 Loading downloads/200425.txt\n",
      "22:59:02 Loading downloads/200502.txt\n",
      "22:59:03 Loading downloads/200509.txt\n",
      "22:59:04 Loading downloads/200516.txt\n",
      "22:59:05 Loading downloads/200523.txt\n",
      "22:59:06 Loading downloads/200530.txt\n",
      "22:59:07 Loading downloads/200606.txt\n",
      "22:59:08 Loading downloads/200613.txt\n",
      "22:59:09 Loading downloads/200620.txt\n",
      "22:59:11 Loading downloads/200627.txt\n",
      "22:59:12 Loading downloads/200704.txt\n",
      "22:59:13 Loading downloads/200711.txt\n",
      "22:59:14 Loading downloads/200718.txt\n",
      "22:59:16 Loading downloads/200725.txt\n",
      "22:59:17 Loading downloads/200801.txt\n",
      "22:59:18 Loading downloads/200808.txt\n",
      "22:59:19 Loading downloads/200815.txt\n",
      "22:59:20 Loading downloads/200822.txt\n",
      "22:59:21 Loading downloads/200829.txt\n",
      "22:59:23 Loading downloads/200905.txt\n",
      "22:59:24 Loading downloads/200912.txt\n",
      "22:59:25 Loading downloads/200919.txt\n",
      "22:59:26 Loading downloads/200926.txt\n",
      "22:59:27 Loading downloads/201003.txt\n",
      "22:59:28 Loading downloads/201010.txt\n",
      "22:59:29 Loading downloads/201017.txt\n",
      "22:59:31 Loading downloads/201024.txt\n",
      "22:59:32 Loading downloads/201031.txt\n",
      "22:59:33 Loading downloads/201107.txt\n",
      "22:59:34 Loading downloads/201114.txt\n",
      "22:59:35 Loading downloads/201121.txt\n",
      "22:59:37 Loading downloads/201128.txt\n",
      "22:59:38 Loading downloads/201205.txt\n",
      "22:59:39 Loading downloads/201212.txt\n",
      "22:59:40 Loading downloads/201219.txt\n",
      "22:59:42 Loading downloads/201226.txt\n",
      "22:59:43 Loading downloads/210102.txt\n",
      "22:59:44 Loading downloads/210109.txt\n",
      "22:59:45 Loading downloads/210116.txt\n",
      "22:59:47 Loading downloads/210123.txt\n",
      "22:59:48 Loading downloads/210130.txt\n",
      "22:59:50 Loading downloads/210206.txt\n",
      "22:59:51 Loading downloads/210213.txt\n",
      "22:59:53 Loading downloads/210220.txt\n",
      "22:59:55 Loading downloads/210227.txt\n",
      "22:59:56 Loading downloads/210306.txt\n",
      "22:59:58 Loading downloads/210313.txt\n",
      "22:59:59 Loading downloads/210320.txt\n",
      "23:00:00 Loading downloads/210327.txt\n",
      "23:00:01 Loading downloads/210403.txt\n",
      "23:00:03 Loading downloads/210410.txt\n",
      "23:00:04 Loading downloads/210417.txt\n",
      "23:00:06 Loading downloads/210424.txt\n",
      "23:00:07 Loading downloads/210501.txt\n",
      "23:00:08 Loading downloads/210508.txt\n",
      "23:00:10 Loading downloads/210515.txt\n",
      "23:00:11 Loading downloads/210522.txt\n",
      "23:00:12 Loading downloads/210529.txt\n",
      "23:00:14 Loading downloads/210605.txt\n",
      "23:00:15 Loading downloads/210612.txt\n",
      "23:00:16 Loading downloads/210619.txt\n",
      "23:00:18 Loading downloads/210626.txt\n",
      "23:00:19 Loading downloads/210703.txt\n",
      "23:00:21 Loading downloads/210710.txt\n",
      "23:00:22 Loading downloads/210717.txt\n",
      "23:00:24 Loading downloads/210724.txt\n",
      "23:00:25 Loading downloads/210731.txt\n",
      "23:00:27 Loading downloads/210807.txt\n",
      "23:00:28 Loading downloads/210814.txt\n",
      "23:00:29 Loading downloads/210821.txt\n",
      "23:00:31 Loading downloads/210828.txt\n",
      "23:00:32 Loading downloads/210904.txt\n",
      "23:00:34 Loading downloads/210911.txt\n",
      "23:00:35 Loading downloads/210918.txt\n",
      "23:00:36 Loading downloads/210925.txt\n",
      "23:00:38 Loading downloads/211002.txt\n",
      "23:00:39 Loading downloads/211009.txt\n",
      "23:00:41 Loading downloads/211016.txt\n",
      "23:00:42 Loading downloads/211023.txt\n",
      "23:00:44 Loading downloads/211030.txt\n",
      "23:00:45 Loading downloads/211106.txt\n",
      "23:00:47 Loading downloads/211113.txt\n",
      "23:00:49 Loading downloads/211120.txt\n",
      "23:00:50 Loading downloads/211127.txt\n",
      "23:00:52 Loading downloads/211204.txt\n",
      "23:00:53 Loading downloads/211211.txt\n",
      "23:00:55 Loading downloads/211218.txt\n",
      "23:00:57 Loading downloads/211225.txt\n",
      "23:00:59 Loading downloads/220101.txt\n",
      "23:01:00 Loading downloads/220108.txt\n",
      "23:01:02 Loading downloads/220115.txt\n",
      "23:01:04 Loading downloads/220122.txt\n",
      "23:01:06 Loading downloads/220129.txt\n",
      "23:01:07 Loading downloads/220205.txt\n",
      "23:01:09 Loading downloads/220212.txt\n",
      "23:01:11 Loading downloads/220219.txt\n",
      "23:01:14 Loading downloads/220226.txt\n",
      "23:01:15 Loading downloads/220305.txt\n",
      "23:01:17 Loading downloads/220312.txt\n",
      "23:01:19 Loading downloads/220319.txt\n",
      "23:01:22 Loading downloads/220326.txt\n",
      "23:01:24 Loading downloads/220402.txt\n",
      "23:01:26 Loading downloads/220409.txt\n",
      "23:01:29 Loading downloads/220416.txt\n",
      "23:01:31 Loading downloads/220423.txt\n",
      "23:01:34 Loading downloads/220430.txt\n",
      "23:01:36 Loading downloads/220507.txt\n",
      "23:01:39 Loading downloads/220514.txt\n",
      "23:01:41 Loading downloads/220521.txt\n",
      "23:01:44 Loading downloads/220528.txt\n",
      "23:01:47 Loading downloads/220604.txt\n",
      "23:01:50 Loading downloads/220611.txt\n",
      "23:01:52 Loading downloads/220618.txt\n",
      "23:01:57 Loading downloads/220625.txt\n",
      "23:02:00 Loading downloads/220702.txt\n",
      "23:02:04 Loading downloads/220709.txt\n",
      "23:02:09 Loading downloads/220716.txt\n",
      "23:02:14 Loading downloads/220723.txt\n",
      "23:02:19 Loading downloads/220730.txt\n",
      "23:02:23 Loading downloads/220806.txt\n",
      "23:02:26 Loading downloads/220813.txt\n",
      "23:02:30 Loading downloads/220820.txt\n",
      "23:02:34 Loading downloads/220827.txt\n",
      "23:02:39 Loading downloads/220903.txt\n",
      "23:02:42 Loading downloads/220910.txt\n",
      "23:02:44 Loading downloads/220917.txt\n",
      "23:02:47 Loading downloads/220924.txt\n",
      "23:02:49 Loading downloads/221001.txt\n",
      "23:02:51 Loading downloads/221008.txt\n",
      "23:02:54 Loading downloads/221015.txt\n",
      "23:02:56 Loading downloads/221022.txt\n",
      "23:02:58 Loading downloads/221029.txt\n",
      "23:03:00 Loading downloads/221105.txt\n",
      "23:03:03 Loading downloads/221112.txt\n",
      "23:03:05 Loading downloads/221119.txt\n",
      "23:03:07 Loading downloads/221126.txt\n",
      "23:03:09 Loading downloads/221203.txt\n",
      "23:03:11 Loading downloads/221210.txt\n",
      "23:03:12 Loading downloads/221217.txt\n",
      "23:03:15 Loading downloads/221224.txt\n",
      "23:03:16 Loading downloads/221231.txt\n",
      "23:03:18 Loading downloads/230107.txt\n",
      "23:03:20 Loading downloads/230114.txt\n"
     ]
    }
   ],
   "source": [
    "datadir = \"downloads\"\n",
    "datafiles = sorted([datadir + \"/\" + f for f in listdir(datadir) if f[-4:]==\".txt\"])\n",
    "\n",
    "for f in datafiles:\n",
    "    print (\"%s Loading %s\" % (strftime(\"%H:%M:%S\"), f))\n",
    "    %sql insert into temp_data SELECT * FROM read_csv(:f, \\\n",
    "                                                      delim=',', \\\n",
    "                                                      header=True, \\\n",
    "                                                      columns={'C/A': 'VARCHAR', \\\n",
    "                                                               'UNIT': 'VARCHAR', \\\n",
    "                                                               'SCP': 'VARCHAR', \\\n",
    "                                                               'STATION': 'VARCHAR', \\\n",
    "                                                               'LINENAME': 'VARCHAR', \\\n",
    "                                                               'DIVISION': 'VARCHAR', \\\n",
    "                                                               'DATE': 'DATE', \\\n",
    "                                                               'TIME': 'TIME',\\\n",
    "                                                               'DESC': 'VARCHAR',\\\n",
    "                                                               'ENTRIES': 'INTEGER',\\\n",
    "                                                               'EXITS': 'INTEGER',},\\\n",
    "                                                      dateformat='%m/%d/%Y');\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43986355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0      43986355"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 header row in each file\n",
    "# subtract number of files from number of lines found by wc above, should equal this number\n",
    "\n",
    "%sql SELECT COUNT(*) FROM temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>time</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRY_COUNTER</th>\n",
       "      <th>EXIT_COUNTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6889287</td>\n",
       "      <td>2335920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6889299</td>\n",
       "      <td>2335936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6889364</td>\n",
       "      <td>2336038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6889605</td>\n",
       "      <td>2336101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6889966</td>\n",
       "      <td>2336173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6890186</td>\n",
       "      <td>2336219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6890230</td>\n",
       "      <td>2336231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6890237</td>\n",
       "      <td>2336242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6890279</td>\n",
       "      <td>2336288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6890428</td>\n",
       "      <td>2336357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION        DATE      time  \\\n",
       "0  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  03:00:00   \n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  07:00:00   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  11:00:00   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  15:00:00   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  19:00:00   \n",
       "5  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-29  23:00:00   \n",
       "6  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-30  03:00:00   \n",
       "7  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-30  07:00:00   \n",
       "8  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-30  11:00:00   \n",
       "9  A002  R051  02-00-00   59 ST  NQR456W      BMT  2018-12-30  15:00:00   \n",
       "\n",
       "      DESC  ENTRY_COUNTER  EXIT_COUNTER  \n",
       "0  REGULAR        6889287       2335920  \n",
       "1  REGULAR        6889299       2335936  \n",
       "2  REGULAR        6889364       2336038  \n",
       "3  REGULAR        6889605       2336101  \n",
       "4  REGULAR        6889966       2336173  \n",
       "5  REGULAR        6890186       2336219  \n",
       "6  REGULAR        6890230       2336231  \n",
       "7  REGULAR        6890237       2336242  \n",
       "8  REGULAR        6890279       2336288  \n",
       "9  REGULAR        6890428       2336357  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from temp_data limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.OutOfMemoryException) Out of Memory Error: could not allocate block of 262144 bytes (6676025344/6676149043 used) \n",
      "[SQL: create table mta as SELECT distinct * FROM \"temp_data\" ;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: SELECT COUNT(*) FROM mta\n",
      "                             ^\n",
      "[SQL: SELECT COUNT(*) FROM mta]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# deduplicate rows\n",
    "%sql create table mta as SELECT distinct * FROM \"temp_data\" ;\n",
    "%sql drop table temp_data;\n",
    "%sql SELECT COUNT(*) FROM mta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: delete from mta where \"DESC\" = 'RECOVR AUD' ;\n",
      "                    ^\n",
      "[SQL: delete from mta where \"DESC\" = 'RECOVR AUD' ;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: SELECT COUNT(*) FROM mta\n",
      "                             ^\n",
      "[SQL: SELECT COUNT(*) FROM mta]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# remove these audit records ... might need to check if they should always be deleted\n",
    "%sql delete from mta where \"DESC\" = 'RECOVR AUD';\n",
    "%sql SELECT COUNT(*) FROM mta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "[SQL: alter table mta add column DATE_TIME timestamp;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set DATE_TIME = make_timestamp(date...\n",
      "               ^\n",
      "[SQL: update mta set DATE_TIME = make_timestamp(date_part('year', date), date_part('month', date), date_part('day', date),date_part('hour', TIME), date_part('minute', TIME), date_part('second', TIME))]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# add timestamp from date/time\n",
    "%sql alter table mta add column DATE_TIME timestamp;\n",
    "%sql update mta set DATE_TIME = make_timestamp(date_part('year', date), date_part('month', date), date_part('day', date),date_part('hour', TIME), date_part('minute', TIME), date_part('second', TIME))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "[SQL: alter table mta add column TURNSTILE VARCHAR;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set TURNSTILE = CONCAT(\"C/A\" , ' ' ...\n",
      "               ^\n",
      "[SQL: update mta set TURNSTILE = CONCAT(\"C/A\" , ' ' , UNIT , ' ' , SCP)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# make unique turnstile labels\n",
    "%sql alter table mta add column TURNSTILE VARCHAR;\n",
    "%sql update mta set TURNSTILE = CONCAT(\"C/A\" , ' ' , UNIT , ' ' , SCP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = concat(station, '-' ,...\n",
      "               ^\n",
      "[SQL: update mta set station = concat(station, '-' , linename);]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# make unique station names, else you have '7 AV' in Manhattan, Brooklyn, multiple \"23 St\" etc\n",
    "%sql update mta set station = concat(station, '-', linename);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ST-UNION SQ-LNQR456W -> 14 ST-UNION SQ-456LNQRW\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('14 ST-UNION SQ-456LNQRW', '14 ST-UNION SQ-LNQR456W')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "161/YANKEE STAD-BD4 -> 161/YANKEE STAD-4BD\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('161/YANKEE STAD-4BD', '161/YANKEE STAD-BD4')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "34 ST-PENN STA-123 -> 34 ST-PENN STA-123ACE\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('34 ST-PENN STA-123ACE', '34 ST-PENN STA-123')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "34 ST-PENN STA-ACE -> 34 ST-PENN STA-123ACE\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('34 ST-PENN STA-123ACE', '34 ST-PENN STA-ACE')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "42 ST-PORT AUTH-ACENGRS1237W -> 42 ST-PORT AUTH-ACENQRS1237W\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('42 ST-PORT AUTH-ACENQRS1237W', '42 ST-PORT AUTH-ACENGRS1237W')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "59 ST-NQR456W -> 59 ST-456NQRW\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('59 ST-456NQRW', '59 ST-NQR456W')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "59 ST-NRW -> 59 ST-456NQRW\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('59 ST-456NQRW', '59 ST-NRW')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "59 ST COLUMBUS-ABCD1 -> 59 ST COLUMBUS-1ABCD\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('59 ST COLUMBUS-1ABCD', '59 ST COLUMBUS-ABCD1')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "ATL AV-BARCLAY-BDNQR2345 -> ATL AV-BARCLAY-2345BDNQR\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('ATL AV-BARCLAY-2345BDNQR', 'ATL AV-BARCLAY-BDNQR2345')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "BOROUGH HALL-R2345 -> BOROUGH HALL-2345R\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('BOROUGH HALL-2345R', 'BOROUGH HALL-R2345')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "COURT SQ-23 ST-EMG -> COURT SQ-EMG\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('COURT SQ-EMG', 'COURT SQ-23 ST-EMG')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "FULTON ST-ACJZ2345 -> FULTON ST-2345ACJZ\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('FULTON ST-2345ACJZ', 'FULTON ST-ACJZ2345')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "GUN HILL RD-5 -> GUN HILL RD-25\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('GUN HILL RD-25', 'GUN HILL RD-5')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "PATH WTC 2-PTH-1 -> PATH NEW WTC-PTH-1\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('PATH NEW WTC-PTH-1', 'PATH WTC 2-PTH-1')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "PELHAM PKWY-5 -> PELHAM PKWY-25\n",
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: update mta set station = ? where station = ?;\n",
      "               ^\n",
      "[SQL: update mta set station = ? where station = ?;]\n",
      "[parameters: ('PELHAM PKWY-25', 'PELHAM PKWY-5')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "# fix some issues with same station having multiple names\n",
    "# in ideal world would cross-reference MTA station list\n",
    "fixes = {\n",
    "    '14 ST-UNION SQ-LNQR456W': '14 ST-UNION SQ-456LNQRW',\n",
    "    '161/YANKEE STAD-BD4': '161/YANKEE STAD-4BD',\n",
    "    '34 ST-PENN STA-123': '34 ST-PENN STA-123ACE',\n",
    "    '34 ST-PENN STA-ACE': '34 ST-PENN STA-123ACE',\n",
    "    '42 ST-PORT AUTH-ACENGRS1237W': '42 ST-PORT AUTH-ACENQRS1237W',\n",
    "    '59 ST-NQR456W': '59 ST-456NQRW',\n",
    "    '59 ST-NRW': '59 ST-456NQRW',\n",
    "    '59 ST COLUMBUS-ABCD1': '59 ST COLUMBUS-1ABCD',\n",
    "    'ATL AV-BARCLAY-BDNQR2345': 'ATL AV-BARCLAY-2345BDNQR',\n",
    "    'BOROUGH HALL-R2345': 'BOROUGH HALL-2345R',\n",
    "    'COURT SQ-23 ST-EMG': 'COURT SQ-EMG',\n",
    "    'FULTON ST-ACJZ2345': 'FULTON ST-2345ACJZ',\n",
    "    'GUN HILL RD-5': 'GUN HILL RD-25',\n",
    "    'PATH WTC 2-PTH-1': 'PATH NEW WTC-PTH-1',\n",
    "    'PELHAM PKWY-5': 'PELHAM PKWY-25',\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in fixes.items():\n",
    "    print(k, '->', v)\n",
    "    %sql update mta set station = :v where station = :k;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name mta does not exist!\n",
      "Did you mean \"pg_am\"?\n",
      "LINE 1: SELECT station, count(*) FROM mta group by station order by station;\n",
      "                                      ^\n",
      "[SQL: SELECT station, count(*) FROM mta group by station order by station;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%sql SELECT station, count(*) FROM mta group by station order by station;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name mta does not exist!\nDid you mean \"pg_am\"?\nLINE 1: SELECT station, count(*) FROM mta group by station order by station;\n                                      ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m con \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmta.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT station, count(*) FROM mta group by station order by station;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m con\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name mta does not exist!\nDid you mean \"pg_am\"?\nLINE 1: SELECT station, count(*) FROM mta group by station order by station;\n                                      ^"
     ]
    }
   ],
   "source": [
    "# not sure why %sql magic sometimes doesn't display table here  \n",
    "con = duckdb.connect('mta.db')\n",
    "query = \"SELECT station, count(*) FROM mta group by station order by station;\"\n",
    "con.execute(query)\n",
    "con.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE mta DROP LINENAME;\n",
    "ALTER TABLE mta DROP DIVISION;\n",
    "ALTER TABLE mta DROP \"DESC\";\n",
    "ALTER TABLE mta DROP TIME;\n",
    "ALTER TABLE mta DROP \"C/A\";\n",
    "ALTER TABLE mta DROP UNIT;\n",
    "ALTER TABLE mta DROP SCP;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PRAGMA database_size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"PRAGMA database_size;\"\n",
    "# con.execute(query)\n",
    "# con.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Ending DuckDB initial load\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data quality with DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if each turnstile is available for each station for each time, compute % time coverage vs. expected\n",
    "- check any overlapping time periods by turnstile \n",
    "- compute change in entries, exits by turnstile by time\n",
    "- fix negatives\n",
    "- fix outliers, usually indicate maintenance reset count \n",
    "\n",
    "Should review articles and Todd Schneider code for additional data quality checks and fixes. Could possibly add better data quality with\n",
    "\n",
    "- https://greatexpectations.io/\n",
    "- https://pandera.readthedocs.io/en/stable/\n",
    "- https://github.com/awslabs/python-deequ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Starting diff and DQ\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists mta_diff;\n",
    "\n",
    "CREATE TABLE mta_diff AS \n",
    "SELECT DATE, DATE_TIME, STATION, TURNSTILE, \n",
    "ENTRY_COUNTER,\n",
    "ENTRY_COUNTER - lag(ENTRY_COUNTER) OVER (PARTITION BY STATION, TURNSTILE ORDER BY DATE_TIME) AS ENTRIES,\n",
    "2000 ENTRIES_CUTOFF ,\n",
    "EXIT_COUNTER,\n",
    "EXIT_COUNTER - lag(EXIT_COUNTER) OVER (PARTITION BY STATION, TURNSTILE ORDER BY DATE_TIME) AS EXITS,\n",
    "2000 EXITS_CUTOFF\n",
    "FROM mta;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql describe mta_diff;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from mta_diff order by station, turnstile, date_time limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql drop table mta;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE mta_diff drop column ENTRY_COUNTER;\n",
    "%sql ALTER TABLE mta_diff drop column EXIT_COUNTER;\n",
    "%sql ALTER TABLE mta_diff RENAME TO mta;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse mta\n",
    "# qgrid gives a sortable table but seems to have compatibility issues\n",
    "%sql df << SELECT * FROM mta where station ='ORCHARD BEACH-6'\n",
    "# show_grid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select DATE_TIME, STATION, TURNSTILE, count(*) from mta\n",
    "group by DATE_TIME, STATION, TURNSTILE\n",
    "having count(*) > 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fix <=0, sometimes maintenance is done, resets turnstile counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows at start of window with no diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta\n",
    "where entries is null \n",
    "and exits is null;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where ENTRIES < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where EXITS < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where ENTRIES < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where EXITS < 0;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping bad rows\n",
    "\n",
    "- Taking a slightly more permissive approach than cutting off everything > 2K\n",
    "- Looking at e.g. BEDFORD AV-L\tH009\tR235\t00-03-04 , does 2000 on the regular\n",
    "- First cut off everything > 6K. Every 2s = 7200 in 4h period. but I wonder if sometimes the period is longer? I could see a deal at a massive event where trains keep coming and there is always a queue at a turnstile\n",
    "- Then compute average, sd, count by turnstile\n",
    "- if count < 20 then cut off everything > 2K\n",
    "- if count >= 20 then cut off everything based on SD, with a 1K minmimum threshold\n",
    "- Seems to call for some kind of bayesian approach, maybe use one of the DQ packages\n",
    "    - for each new turnstile start with a prior distribution on the turnstile mean and sd based on all the turnstiles\n",
    "    - for each observation at that turnstile, update the prior\n",
    "    - at the end , discard the observations that are eg 4 updated sds from the updated mean. (we should think about what sort of true distribution there is, how many we will discard, what the tradeoff is for rejecting a row incorrectly).\n",
    "    - so if you only have 1 observation, you'll be discarding based on close to the population mean and sd\n",
    "    - if you have 30 observations, you'll be discarding based on close to the turnstile mean and sd\n",
    "    - also if there was turnstile maintenance both entries and exits should be off, can add signal and reduce sd threshold and require both to be off (not doing this)\n",
    "     - IMO it's pretty easy for something weird to happen where something goes to a different mode, flood or cops or something closes an entrance, 1-time big event. Seems like a good DQ framework needs a flexible rule plus some whitelisted days/exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard 7200 limit per turnstile per period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where ENTRIES > 7200;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where EXITS > 7200;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where ENTRIES>7200;\n",
    "delete from mta where EXITS>7200;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average, sd, observation count by turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists entry_avg;\n",
    "create table entry_avg as \n",
    "select station, TURNSTILE, avg(entries) MEAN, stddev(entries) SD, count(*) N, \n",
    "from mta\n",
    "where entries > 0\n",
    "group by station, TURNSTILE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select * from entry_avg order by MEAN desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from entry_avg where turnstile ='N078 R175 01-06-00'\n",
    "limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from mta\n",
    "where turnstile ='N078 R175 01-06-00'\n",
    "order by entries desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table entry_avg add column ENTRIES_CUTOFF DOUBLE;\n",
    "update entry_avg set ENTRIES_CUTOFF = MEAN + 3 * SD;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where N <= 20;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where ENTRIES_CUTOFF > 100000;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where isnan(ENTRIES_CUTOFF);\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where ENTRIES_CUTOFF < 2000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "update mta \n",
    "set ENTRIES_CUTOFF = (\n",
    "select ENTRIES_CUTOFF from entry_avg\n",
    "    where\n",
    "    entry_avg.station = mta.station and \n",
    "    entry_avg.turnstile = mta.turnstile\n",
    ")\n",
    "where exists (\n",
    "    select 1 from entry_avg\n",
    "    where\n",
    "    entry_avg.station = mta.station and \n",
    "    entry_avg.turnstile = mta.turnstile\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists exit_avg;\n",
    "create table exit_avg as \n",
    "select station, TURNSTILE, avg(exits) MEAN, stddev(exits) SD, count(*) N, \n",
    "from mta\n",
    "where exits > 0\n",
    "group by station, TURNSTILE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from exit_avg order by MEAN desc limit 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from mta where turnstile='N012 R035 01-05-01'\n",
    "order by exits desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table exit_avg add column EXITS_CUTOFF DOUBLE;\n",
    "update exit_avg set EXITS_CUTOFF = MEAN + 3 * SD;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where N <= 20;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where EXITS_CUTOFF > 100000;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where isnan(EXITS_CUTOFF);\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where EXITS_CUTOFF < 2000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "update mta\n",
    "set EXITS_CUTOFF = (\n",
    "select EXITS_CUTOFF from exit_avg\n",
    "    where\n",
    "    exit_avg.station = mta.station and \n",
    "    exit_avg.turnstile = mta.turnstile \n",
    ")\n",
    "where exists (\n",
    "    select 1 from exit_avg\n",
    "    where\n",
    "    exit_avg.station = mta.station and \n",
    "    exit_avg.turnstile = mta.turnstile\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s deleting based on cutoff\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard cutoff, delete if either exits or entries exceeds. \n",
    "# although if a technical issue both entries and exits should be off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "delete from mta where entries > entries_cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where exits > exits_cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where entries=0 and exits=0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Finishing diff and DQ\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PRAGMA database_size;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Starting aggregation and dataviz\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "df << select DATE, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "group by date\n",
    "order by date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "select DATE, sum(ENTRIES) ENTRIES from mta\n",
    "group by DATE\n",
    "order by DATE\n",
    "\"\"\")\n",
    "df = pd.DataFrame(con.fetchall(), columns=['DATE', 'ENTRIES'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"rolling\"] = df['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"DATE\"], df[\"rolling\"])\n",
    "plt.title(\"NYC Subway Entries - All, 7-day Moving Average\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_stations = ['1 AV-L',\n",
    "'14 ST-123FLM',\n",
    "'14 ST-ACEL',\n",
    "'14 ST-UNION SQ-456LNQRW',\n",
    "'14TH STREET-1',\n",
    "'18 ST-1',\n",
    "'2 AV-F',\n",
    "'23 ST-1',\n",
    "'23 ST-6',\n",
    "'23 ST-CE',\n",
    "'23 ST-FM',\n",
    "'23 ST-NRW',\n",
    "'28 ST-1',\n",
    "'28 ST-6',\n",
    "'28 ST-NRW',\n",
    "'3 AV-L',\n",
    "'33 ST-6',\n",
    "'34 ST-HERALD SQ-BDFMNQRW',\n",
    "'34 ST-HUDSON YD-7',\n",
    "'34 ST-PENN STA-123',\n",
    "'34 ST-PENN STA-123ACE',\n",
    "'34 ST-PENN STA-ACE',\n",
    "'42 ST-BRYANT PK-7BDFM',\n",
    "'42 ST-PORT AUTH-1237ACEGNRSW',\n",
    "'42 ST-PORT AUTH-1237ACENQRSW',\n",
    "'47-50 STS ROCK-BDFM',\n",
    "'49 ST-NQRW',\n",
    "'5 AV/53 ST-EM',\n",
    "'5 AV/59 ST-NQRW',\n",
    "'5 AVE-7BDFM',\n",
    "'50 ST-1',\n",
    "'50 ST-CE',\n",
    "'50 ST-D',\n",
    "'51 ST-6',\n",
    "'57 ST-7 AV-NQRW',\n",
    "'57 ST-F',\n",
    "'59 ST COLUMBUS-1ABCD',\n",
    "'59 ST-456NQRW',\n",
    "'59 ST-NRW',\n",
    "'6 AV-123FLM',\n",
    "'7 AV-BDE',\n",
    "'8 AV-ACEL',\n",
    "'8 ST-NYU-NRW',\n",
    "'9TH STREET-1',\n",
    "'ASTOR PL-6',\n",
    "\"B'WAY-LAFAYETTE-6BDFQ\",\n",
    "'BLEECKER ST-6DF',\n",
    "'BOWLING GREEN-45',\n",
    "'BROAD ST-JZ',\n",
    "'BROOKLYN BRIDGE-456JZ',\n",
    "'CANAL ST-1',\n",
    "'CANAL ST-6JNQRWZ',\n",
    "'CANAL ST-ACE',\n",
    "'CHAMBERS ST-123',\n",
    "'CHAMBERS ST-23ACE',\n",
    "'CHAMBERS ST-456JZ',\n",
    "'CHRISTOPHER ST-1',\n",
    "'CITY HALL-NRW',\n",
    "'CORTLANDT ST-NRW',\n",
    "'DELANCEY/ESSEX-FJMZ',\n",
    "'EAST BROADWAY-F',\n",
    "'EXCHANGE PLACE-1',\n",
    "'FRANKLIN ST-1',\n",
    "'FULTON ST-2345ACJZ',\n",
    "'GRAND ST-BD',\n",
    "'GRD CNTRL-42 ST-4567S',\n",
    "'HOUSTON ST-1',\n",
    "'LEXINGTON AV/53-6EM',\n",
    "'LEXINGTON AV/63-F',\n",
    "'PARK PLACE-23ACE',\n",
    "'PATH NEW WTC-1',\n",
    "'PATH WTC 2-1',\n",
    "'PRINCE ST-NRW',\n",
    "'RECTOR ST-1',\n",
    "'RECTOR ST-NRW',\n",
    "'SOUTH FERRY-1RW',\n",
    "'SPRING ST-6',\n",
    "'SPRING ST-CE',\n",
    "'TIMES SQ-42 ST-1237ACENQRS',\n",
    "'TIMES SQ-42 ST-1237ACENQRSW',\n",
    "'TWENTY THIRD ST-1',\n",
    "'W 4 ST-WASH SQ-ABCDEFM',\n",
    "'WALL ST-23',\n",
    "'WALL ST-45',\n",
    "'WHITEHALL S-FRY-1RW',\n",
    "'WORLD TRADE CTR-23ACE',\n",
    "'WTC-CORTLANDT-1',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql df << select DATE, STATION, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "group by DATE, STATION\n",
    "order by entries desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "select DATE, STATION, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "group by DATE, STATION\n",
    "order by entries desc;\n",
    "\"\"\")\n",
    "df = pd.DataFrame(con.fetchall(), columns=['DATE', 'STATION', 'ENTRIES'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan < 66 st\n",
    "# before 11am on weekday\n",
    "cbd_df = df.loc[df[\"STATION\"].isin(cbd_stations)].copy()\n",
    "len(cbd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df = cbd_df[['DATE', 'ENTRIES']].groupby(\"DATE\") \\\n",
    "    .sum() \\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df[\"rolling\"] = cbd_df['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "\n",
    "plt.plot(cbd_df[\"DATE\"], cbd_df[\"rolling\"])\n",
    "plt.title(\"NYC Subway Entries - CBD, 7-day Moving Average\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "df << select DATE, DATE_TIME, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "where ENTRIES > 0\n",
    "group by DATE, DATE_TIME\n",
    "order by DATE, DATE_TIME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "select DATE, DATE_TIME, sum(ENTRIES) ENTRIES from mta group by DATE, DATE_TIME\n",
    "order by DATE, DATE_TIME\n",
    "\"\"\")\n",
    "df = pd.DataFrame(con.fetchall(), columns=['DATE', 'DATE_TIME', 'ENTRIES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df[\"DATE_TIME\"].dt.weekday\n",
    "df[\"hour\"] = df[\"DATE_TIME\"].dt.hour\n",
    "\n",
    "morn_df = df.loc[df[\"weekday\"] < 5]\n",
    "df_am = morn_df.loc[df[\"hour\"] < 12]\n",
    "df_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ent = df_am[[\"DATE\", \"ENTRIES\"]] \\\n",
    "    .groupby([\"DATE\"]) \\\n",
    "    .sum() \\\n",
    "    .reset_index() \\\n",
    "    .copy()\n",
    "\n",
    "agg_ent[\"rolling\"] = agg_ent['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "agg_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agg_ent[\"DATE\"], agg_ent[\"rolling\"])\n",
    "plt.title(\"Entries - Weekday Mornings\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s all done!\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest year list and map  \n",
    "# pandemic list and map\n",
    "# 2019 list and map\n",
    "# same 3 lists and map with % change\n",
    "# day of week, cbd filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds",
   "language": "python",
   "name": "mds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
