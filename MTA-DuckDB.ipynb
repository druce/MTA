{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coalesce to clean up updates\n",
    "# get rid of dbt_dv, target one schema\n",
    "# load geo table and line up stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers With Wings: Modern Data Stacks and Pipelines.\n",
    "\n",
    "With apologies to [The Bongos](https://www.youtube.com/watch?v=XdPNmHJNQpc)\n",
    "\n",
    "Suppose you want a dashboard that updates itself when new data is available.\n",
    "\n",
    "For instance, as of January 1, I have some notebooks and blog posts I should update with full-year 2022 data, although I usually don't. It would be nice to have that all happen automatically.\n",
    "\n",
    "We need 6 things to run a data pipeline:\n",
    "\n",
    "1. A scheduler / orchestrator to check for new data and trigger jobs when data is available: maybe on a schedule, maybe monitoring a local directory, maybe polling a remote directory, maybe receiving emails or other signals.\n",
    "\n",
    "2. Tools to manage dependency graphs ([DAGs](https://en.wikipedia.org/wiki/Directed_acyclic_graph)) to trigger jobs like db build, data quality, ML training, inference, notifications downstream when jobs succeed or fail.\n",
    "\n",
    "3. Tools to fetch data from REST APIs, CSVs etc via standard protocols. Built-in schemas for e.g. Zoom or Salesforce would be nice.\n",
    "\n",
    "4. Tools to munge data, extract, load, and transform (ELT). (1) (2)\n",
    "\n",
    "5. Data storage to manage the data and let us query it and aggregate it: DBMS, data warehouse, data lake, lakehouse etc.\n",
    "\n",
    "6. Front end frameworks to create dataviz, reports, dashboards and end-user apps\n",
    "\n",
    "This is just one way to slice the salami. It might be simpler to break down into ELT, data warehouse, BI/front end. In practice 1, 2, and 3 can overlap but there are usually multiple products. There are also [additional pieces](https://i.redd.it/pdnuk1r0yjf71.jpg), like [monitoring pipelines](https://www.acceldata.io/article/what-is-data-pipeline-monitoring) in production, [data quality](https://greatexpectations.io/), [data governance](https://www.collibra.com/us/en/products/data-governance). You can go [pretty deep](https://mattturck.wpenginepowered.com/wp-content/uploads/2021/12/2021-MAD-Landscape-v3.pdf). But this is a reasonable starting framework.\n",
    " \n",
    "How can we build a basic [modern data stack](https://www.getdbt.com/blog/future-of-the-modern-data-stack/) with [MTA turnstile source data](https://data.ny.gov/Transportation/Turnstile-Usage-Data-2020/py8k-a8wg) to do something like [this](https://toddwschneider.com/dashboards/nyc-subway-turnstiles/) or [this](https://www.subwayridership.nyc/)?\n",
    "\n",
    "One way is an enterprise-ish 'on-prem' approach (probably in private or public cloud these days):\n",
    "- Spark cluster \n",
    "- Airflow, dbt, Fivetran, Stitch, Airbyte to manage the data pipeline\n",
    "- PowerBI, Tableau, Superset to deliver some dashboards\n",
    "- Django, Appsmith to deliver some end-user apps, with Postgres storage \n",
    "\n",
    "Another approach is to go 'cloud-native', using pay-as-you-go SaaS cloud services\n",
    "- Cloud lakehouse like Snowflake or Databricks (hosted Spark)\n",
    "- Cloud pipeline services like Astronomer, Prefect, Dagster, dbt Cloud\n",
    "- Cloud analytics service, Tableau Cloud, PowerBI SaaS, Preset\n",
    "- Retool, Appsmith Cloud, with hosted Postgres to deliver end-user apps\n",
    "\n",
    "With a cloud-native stack, SMBs can run just about everything with SaaS services like Salesforce, Square, NetSuite, Workday, Mailchimp, Twilio, Zoom. Who needs devs and system admins and MSPs? When you want to build a workflow app, for instance to organize a conference, create some Zoom meetings send some emails and text messages and get paid, build it in Retool to talk to all those SaaS services. \n",
    "\n",
    "But I'm not going to do any of these heavyweight solutions, I just want a lightweight stack to pull data, run an analysis, and display a dashboard on my MacBook or in a container, for a data stack-in-a-box. Tech we will leverage:\n",
    "\n",
    "- [Duckdb](https://duckdb.org/) is like SQLlite, but for column-oriented data; it's a lightweight package that does high-performance multithreaded aggregation using SQL. [Columnar databases are faster for OLAP](https://loonytek.com/2017/05/04/why-analytic-workloads-are-faster-on-columnar-databases/) . For instance, we can usually get orders of magnitude improvement in size/speed using a columnar format like Parquet vs. CSV with binary storage and compression.\n",
    "\n",
    "- [Singer](https://www.singer.io/), an open source project from Stitch, lets us build 'taps' that abstract talking to specific data sources, like CSVs, or Salesforce, or Zoom, or Postgres. So with a config file, we can say, grab data from a CSV, or the Web, or a REST API, load it into DuckDB.\n",
    "\n",
    "- [Meltano](https://meltano.com), an open source project from Gitlab, is a CLI to manage data pipelines, that can ingest data via [Singer taps](https://www.singer.io/#taps) and [Airbyte connectors](https://airbyte.com/connectors). \n",
    "\n",
    "- [dbt](https://www.getdbt.com/blog/future-of-the-modern-data-stack/), the database build tool, from your data warehouse's perspective, is simply a SQL client. But when you write your SQL scripts within the dbt framework, you get almost for free: integration of scripts into an Airflow DAG workflow; logging; self-documentation of every table's provenance; ability to point any script to dev / test / production environments. \n",
    "\n",
    "- [Superset](https://superset.apache.org) is an open source version of Tableau or PowerBI to run a dashboard.\n",
    "\n",
    "This works pretty well, order of magnitude faster than raw pandas. also more production-ready. It's a nice way to understand how the sausage is made. It's undeniably cool, if you grew up in a world where Google didn't exist, to be able to compute Google-style on your laptop or a $20 Hetzner or AWS box. and you can do real work fast with any data source.\n",
    "\n",
    "But of course, if you are a normie business, just get Databricks (hosted Spark) or Snowflake (SQL data warehouse). I mean, there are [a lot of ways](https://www.moderndatastack.xyz/stacks) to skin this cat. No offense to others but those are the dominant SaaS solutions. \n",
    "\n",
    "If you want to roll your own, there are [a lot of ways](https://www.moderndatastack.xyz/stacks) to skin this cat. This dude even has a ['post-modern' data stack](https://blog.devgenius.io/modern-data-stack-demo-5d75dcdfba50). But at this point, rolling your own modern data stack is for teams with scale which is maybe not most teams. Or penniless startups and hobbyists who want to see how the sausage is made and put up a small container with a data app, which is what we did here.\n",
    "\n",
    "On the other hand, if you sub Spark for DuckDB, this hobbyiest data-warehouse-in-a-box starts to look like it could be a decent model for an enterprise stack.\n",
    "\n",
    "(1) footnote: Earlier OLAP manifestations processed data into cubes, sort of like spreadsheets within a database, to batch pre-process aggregations and enable real-time drilldowns. Modern data stacks keep data in close to raw form and leverage parallel processing to transform on the fly. In the extreme (i.e. Spark), we can make a cluster and move a shard of the data to each node in the cluster, moving the data close to the compute and keeping it in RAM. Then each node can do its part of aggregations and drilldowns and send the results to a controller for final compilations, [MapReduce](https://en.wikipedia.org/wiki/MapReduce) paradigm style. Thus ELT in contrast to old-school ETL.\n",
    "\n",
    "(2) footnote: Are clusters dead? [Zen](https://en.wikipedia.org/wiki/Zen_4) changes everything. When Google first came out, the part that truly blew my mind was not the bigger index and better relevance, but the fact that when you ran a search, the results gave not just a URL, but *the excerpt on the page* that matched your search. Google was *caching the entire Web in RAM*. In less than a second, it farmed out your search to dozens of PCs, each of which kept a shard of the database in RAM, got the results from each shard, sorted them and assembled them into a SERP. Google clusters were an unprecedented new paradigm in computing. To make this work, Google built its own ultra-cheap single-thread servers that were just boards zip-tied together. Today the pendulum has swung the other way. It may be *cheaper* to run a giant [AMD Epyc box](https://aws.amazon.com/blogs/aws/new-amazon-ec2-c6a-instances-powered-by-3rd-gen-amd-epyc-processors-for-compute-intensive-workloads/) with 192 cores and 384GB of RAM than equivalent compute on individual servers. You can even rent an [8-socket Intel box with 24 TB of RAM](https://aws.amazon.com/ec2/instance-types/high-memory/)! Big data, in the sense of data too big to fit on a single box in RAM, hardly exists outside Big Tech. Machines have grown even faster than tabular datasets. Giant CPUs also change the way software is built, for super high performance services you may want to [pin each thread to a core](https://twitter.com/alexxubyte/status/1588203762945884160), keep everything in on-CPU cache, and never context-switch  . As Moore's law dies, it's more about giant dies for a system-on-a-chip, and in our case a modern data stack-in-a-box, as opposed to clusters. For a lot of apps, vertical is the new horizontal.\n",
    "\n",
    "(3) footnote: part of me feels like, if you're a relational database, you had one job, provide a robust, performant abstraction to tabular data. It feels code-smelly to have to use a totally different RDBMS engine for column-oriented vs row-oriented. SQL Server has had COLUMNSTORE for 10 years, even if big data folks don't consider it a true data warehouse. Maybe the traditional RDBMS will incorporate better column-oriented functionality and keep all the good stuff like transactions and query optimization. Or maybe everyone will have to query a [plethora of database engines](https://db-engines.com/en/ranking) and data lakes and we'll need a SQL layer on top of them all to complicate our lives with federated joins and distributed transactions. Oy. Possibly that's the niche that tools like [Trino](https://trino.io/) (f/k/a Presto) are looking to fill. Data seems like the mother of all leaky abstractions, you don't get good performance if you don't know a fair amount about what's going on under the hood. DBAs and data engineers are maybe not going away. Or maybe it's so hard that a lot of people will just put the data into managed cloud services optimized for their use case.\n",
    "\n",
    "may all your pipelines be unjammed and let the data flow \n",
    "https://www.youtube.com/shorts/QIrK40UneH0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from time import strftime\n",
    "from os import listdir, system\n",
    "import pickle\n",
    "import requests\n",
    "from pathlib import Path\n",
    " \n",
    "import pandas as pd\n",
    "# modin uses multithreading but doesn't play well with sql magic\n",
    "# import modin.pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "import duckdb\n",
    "\n",
    "# Import ipython-sql Jupyter extension to create SQL cells\n",
    "%load_ext sql\n",
    "# directly output data to Pandas and to simplify the output that is printed to the notebook.\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "pd.options.display.max_rows=100\n",
    "\n",
    "# Connect ipython-sql to DuckDB using a SQLAlchemy-style connection string. You may either connect to an in memory DuckDB, or a file backed db.\n",
    "%sql duckdb:///mta.db\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data overview](https://data.ny.gov/api/views/py8k-a8wg/files/535bc30e-4119-4992-a799-65d1a05849d4?download=true&filename=MTA_Turnstile_Data_Overview.pdf)\n",
    "- [Data dictionary](https://data.ny.gov/api/views/py8k-a8wg/files/5c602688-3031-4f39-8f2b-d4a3cd8c3752?download=true&filename=MTA_Turnstile_Data_DataDictionary.pdf)\n",
    "- [List of stations](http://web.mta.info/developers/data/nyct/subway/Stations.csv)\n",
    "- [Alt station list](https://data.cityofnewyork.us/api/views/kk4q-3rt2/rows.csv)\n",
    "- [Things to watch out for while working with the MTA turnstile data in 2022](https://towardsai.net/p/l/things-to-watch-out-for-while-working-with-the-mta-turnstile-data-in-2022#:~:text=Additionally%2C%20there%20may%20be%20a,missed%20audit%20that%20was%20recovered.)\n",
    "- [Taming the MTA's unruly turnstile data](https://medium.com/qri-io/taming-the-mtas-unruly-turnstile-data-c945f5f96ba0)\n",
    "- [Todd Schneider repo](https://github.com/toddwschneider/nyc-subway-turnstile-data)\n",
    "- [Sonny Ng project](https://www.subwayridership.nyc/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch raw data files\n",
    "# for any missing saturday after start_date and before today\n",
    "    \n",
    "downloaddir = \"downloads\"\n",
    "csvdir = \"csv\"\n",
    "prefix = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_\"\n",
    "suffix = \".txt\"\n",
    "start_date = date(2019, 1, 7) # start with 1st full week of 2019\n",
    "end_date = date.today()\n",
    "delta = end_date - start_date   # returns timedelta\n",
    "\n",
    "alldays = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "alldays = [day for day in alldays if day.weekday() == 5]\n",
    "\n",
    "for d in alldays:\n",
    "    inix=strftime(\"%y%m%d\", d.timetuple())\n",
    "    url = \"%s%s%s\" % (prefix, inix, suffix)\n",
    "    src = \"%s/%s%s\" % (downloaddir, inix, suffix)\n",
    "    \n",
    "    if Path(src).is_file():\n",
    "        continue\n",
    "    \n",
    "    cmd = \"curl %s > %s\" % (url, src)\n",
    "    print(cmd)\n",
    "    system(cmd)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['downloads/190112.txt', 'downloads/190119.txt', 'downloads/190126.txt']\n",
      "['downloads/221217.txt', 'downloads/221224.txt', 'downloads/221231.txt']\n"
     ]
    }
   ],
   "source": [
    "datadir = \"downloads\"\n",
    "datafiles = sorted([\"downloads/\" + f for f in listdir(datadir) if f[-4:]==\".txt\"])\n",
    "print(len(datafiles))\n",
    "print(datafiles[:3])\n",
    "print(datafiles[-3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  201091 downloads/190112.txt\n",
      "  204728 downloads/190119.txt\n",
      "  201600 downloads/190126.txt\n",
      "  202913 downloads/190202.txt\n",
      "  202736 downloads/190209.txt\n",
      "  204738 downloads/190216.txt\n",
      "  204056 downloads/190223.txt\n",
      "  203190 downloads/190302.txt\n",
      "  203988 downloads/190309.txt\n",
      "  201793 downloads/190316.txt\n",
      "  202723 downloads/190323.txt\n",
      "  204596 downloads/190330.txt\n",
      "  202965 downloads/190406.txt\n",
      "  204712 downloads/190413.txt\n",
      "  202548 downloads/190420.txt\n",
      "  203858 downloads/190427.txt\n",
      "  206858 downloads/190504.txt\n",
      "  204089 downloads/190511.txt\n",
      "  208682 downloads/190518.txt\n",
      "  203364 downloads/190525.txt\n",
      "  203796 downloads/190601.txt\n",
      "  205012 downloads/190608.txt\n",
      "  204935 downloads/190615.txt\n",
      "  207478 downloads/190622.txt\n",
      "  205964 downloads/190629.txt\n",
      "  209539 downloads/190706.txt\n",
      "  208798 downloads/190713.txt\n",
      "  209007 downloads/190720.txt\n",
      "  206531 downloads/190727.txt\n",
      "  206997 downloads/190803.txt\n",
      "  205876 downloads/190810.txt\n",
      "  208567 downloads/190817.txt\n",
      "  205670 downloads/190824.txt\n",
      "  205264 downloads/190831.txt\n",
      "  204796 downloads/190907.txt\n",
      "  205586 downloads/190914.txt\n",
      "  204929 downloads/190921.txt\n",
      "  205337 downloads/190928.txt\n",
      "  206604 downloads/191005.txt\n",
      "  206860 downloads/191012.txt\n",
      "  206820 downloads/191019.txt\n",
      "  205596 downloads/191026.txt\n",
      "  206047 downloads/191102.txt\n",
      "  207617 downloads/191109.txt\n",
      "  204984 downloads/191116.txt\n",
      "  205533 downloads/191123.txt\n",
      "  205545 downloads/191130.txt\n",
      "  205925 downloads/191207.txt\n",
      "  205188 downloads/191214.txt\n",
      "  207606 downloads/191221.txt\n",
      "  206708 downloads/191228.txt\n",
      "  206500 downloads/200104.txt\n",
      "  206074 downloads/200111.txt\n",
      "  205622 downloads/200118.txt\n",
      "  205102 downloads/200125.txt\n",
      "  205142 downloads/200201.txt\n",
      "  205921 downloads/200208.txt\n",
      "  205730 downloads/200215.txt\n",
      "  206184 downloads/200222.txt\n",
      "  207018 downloads/200229.txt\n",
      "  207884 downloads/200307.txt\n",
      "  203966 downloads/200314.txt\n",
      "  206746 downloads/200321.txt\n",
      "  205763 downloads/200328.txt\n",
      "  205667 downloads/200404.txt\n",
      "  205982 downloads/200411.txt\n",
      "  206177 downloads/200418.txt\n",
      "  206363 downloads/200425.txt\n",
      "  206903 downloads/200502.txt\n",
      "  206174 downloads/200509.txt\n",
      "  206906 downloads/200516.txt\n",
      "  206593 downloads/200523.txt\n",
      "  210415 downloads/200530.txt\n",
      "  207893 downloads/200606.txt\n",
      "  206663 downloads/200613.txt\n",
      "  206740 downloads/200620.txt\n",
      "  206672 downloads/200627.txt\n",
      "  208881 downloads/200704.txt\n",
      "  206349 downloads/200711.txt\n",
      "  206263 downloads/200718.txt\n",
      "  206985 downloads/200725.txt\n",
      "  206705 downloads/200801.txt\n",
      "  207113 downloads/200808.txt\n",
      "  206782 downloads/200815.txt\n",
      "  209762 downloads/200822.txt\n",
      "  217833 downloads/200829.txt\n",
      "  208052 downloads/200905.txt\n",
      "  210586 downloads/200912.txt\n",
      "  209662 downloads/200919.txt\n",
      "  209831 downloads/200926.txt\n",
      "  212159 downloads/201003.txt\n",
      "  210221 downloads/201010.txt\n",
      "  207668 downloads/201017.txt\n",
      "  211325 downloads/201024.txt\n",
      "  211985 downloads/201031.txt\n",
      "  213106 downloads/201107.txt\n",
      "  208777 downloads/201114.txt\n",
      "  210258 downloads/201121.txt\n",
      "  209779 downloads/201128.txt\n",
      "  209781 downloads/201205.txt\n",
      "  210404 downloads/201212.txt\n",
      "  210923 downloads/201219.txt\n",
      "  212300 downloads/201226.txt\n",
      "  210434 downloads/210102.txt\n",
      "  210167 downloads/210109.txt\n",
      "  209882 downloads/210116.txt\n",
      "  208846 downloads/210123.txt\n",
      "  208916 downloads/210130.txt\n",
      "  209080 downloads/210206.txt\n",
      "  208622 downloads/210213.txt\n",
      "  209045 downloads/210220.txt\n",
      "  209928 downloads/210227.txt\n",
      "  209076 downloads/210306.txt\n",
      "  209318 downloads/210313.txt\n",
      "  207055 downloads/210320.txt\n",
      "  209471 downloads/210327.txt\n",
      "  209069 downloads/210403.txt\n",
      "  209567 downloads/210410.txt\n",
      "  209692 downloads/210417.txt\n",
      "  209106 downloads/210424.txt\n",
      "  208971 downloads/210501.txt\n",
      "  209176 downloads/210508.txt\n",
      "  209040 downloads/210515.txt\n",
      "  209316 downloads/210522.txt\n",
      "  208913 downloads/210529.txt\n",
      "  209532 downloads/210605.txt\n",
      "  209507 downloads/210612.txt\n",
      "  209261 downloads/210619.txt\n",
      "  209412 downloads/210626.txt\n",
      "  209831 downloads/210703.txt\n",
      "  209689 downloads/210710.txt\n",
      "  209294 downloads/210717.txt\n",
      "  209400 downloads/210724.txt\n",
      "  209464 downloads/210731.txt\n",
      "  209503 downloads/210807.txt\n",
      "  209245 downloads/210814.txt\n",
      "  209416 downloads/210821.txt\n",
      "  209069 downloads/210828.txt\n",
      "  209736 downloads/210904.txt\n",
      "  209484 downloads/210911.txt\n",
      "  209899 downloads/210918.txt\n",
      "  210401 downloads/210925.txt\n",
      "  210212 downloads/211002.txt\n",
      "  209768 downloads/211009.txt\n",
      "  209998 downloads/211016.txt\n",
      "  209985 downloads/211023.txt\n",
      "  209885 downloads/211030.txt\n",
      "  209229 downloads/211106.txt\n",
      "  212174 downloads/211113.txt\n",
      "  209973 downloads/211120.txt\n",
      "  210190 downloads/211127.txt\n",
      "  210235 downloads/211204.txt\n",
      "  210442 downloads/211211.txt\n",
      "  210141 downloads/211218.txt\n",
      "  210384 downloads/211225.txt\n",
      "  210332 downloads/220101.txt\n",
      "  209630 downloads/220108.txt\n",
      "  209791 downloads/220115.txt\n",
      "  209863 downloads/220122.txt\n",
      "  209648 downloads/220129.txt\n",
      "  210084 downloads/220205.txt\n",
      "  210005 downloads/220212.txt\n",
      "  210619 downloads/220219.txt\n",
      "  209850 downloads/220226.txt\n",
      "  209780 downloads/220305.txt\n",
      "  210239 downloads/220312.txt\n",
      "  207557 downloads/220319.txt\n",
      "  211136 downloads/220326.txt\n",
      "  211020 downloads/220402.txt\n",
      "  211303 downloads/220409.txt\n",
      "  212036 downloads/220416.txt\n",
      "  211087 downloads/220423.txt\n",
      "  211267 downloads/220430.txt\n",
      "  211174 downloads/220507.txt\n",
      "  211017 downloads/220514.txt\n",
      "  210476 downloads/220521.txt\n",
      "  211708 downloads/220528.txt\n",
      "  211610 downloads/220604.txt\n",
      "  211248 downloads/220611.txt\n",
      "  211154 downloads/220618.txt\n",
      "  212413 downloads/220625.txt\n",
      "  211264 downloads/220702.txt\n",
      "  210933 downloads/220709.txt\n",
      "  210933 downloads/220716.txt\n",
      "  210230 downloads/220723.txt\n",
      "  210656 downloads/220730.txt\n",
      "  210959 downloads/220806.txt\n",
      "  211950 downloads/220813.txt\n",
      "  210600 downloads/220820.txt\n",
      "  211048 downloads/220827.txt\n",
      "  212449 downloads/220903.txt\n",
      "  212391 downloads/220910.txt\n",
      "  210699 downloads/220917.txt\n",
      "  210592 downloads/220924.txt\n",
      "  211382 downloads/221001.txt\n",
      "  211004 downloads/221008.txt\n",
      "  210700 downloads/221015.txt\n",
      "  211038 downloads/221022.txt\n",
      "  211473 downloads/221029.txt\n",
      "  211162 downloads/221105.txt\n",
      "  213602 downloads/221112.txt\n",
      "  210826 downloads/221119.txt\n",
      "  209936 downloads/221126.txt\n",
      "  211481 downloads/221203.txt\n",
      "  209987 downloads/221210.txt\n",
      "  210186 downloads/221217.txt\n",
      "  209995 downloads/221224.txt\n",
      "  209751 downloads/221231.txt\n",
      " 43361356 total\n"
     ]
    }
   ],
   "source": [
    "# count the lines\n",
    "!wc -l downloads/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & initial cleanup with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:41:20 Starting DuckDB initial load\n"
     ]
    }
   ],
   "source": [
    "# load into mta.db\n",
    "print (\"%s Starting DuckDB initial load\" % (strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists mta;\n",
    "drop table if exists temp_data;\n",
    "\n",
    "create table temp_data(\n",
    "    \"C/A\" VARCHAR, \n",
    "    UNIT VARCHAR, \n",
    "    SCP VARCHAR, \n",
    "    STATION VARCHAR, \n",
    "    LINENAME VARCHAR, \n",
    "    DIVISION VARCHAR, \n",
    "    DATE DATE, \n",
    "    TIME TIME, \n",
    "    \"DESC\" VARCHAR, \n",
    "    ENTRY_COUNTER INTEGER, \n",
    "    EXIT_COUNTER INTEGER);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloads/190112.txt\n",
      "downloads/190119.txt\n",
      "downloads/190126.txt\n",
      "downloads/190202.txt\n",
      "downloads/190209.txt\n",
      "downloads/190216.txt\n",
      "downloads/190223.txt\n",
      "downloads/190302.txt\n",
      "downloads/190309.txt\n",
      "downloads/190316.txt\n",
      "downloads/190323.txt\n",
      "downloads/190330.txt\n",
      "downloads/190406.txt\n",
      "downloads/190413.txt\n",
      "downloads/190420.txt\n",
      "downloads/190427.txt\n",
      "downloads/190504.txt\n",
      "downloads/190511.txt\n",
      "downloads/190518.txt\n",
      "downloads/190525.txt\n",
      "downloads/190601.txt\n",
      "downloads/190608.txt\n",
      "downloads/190615.txt\n",
      "downloads/190622.txt\n",
      "downloads/190629.txt\n",
      "downloads/190706.txt\n",
      "downloads/190713.txt\n",
      "downloads/190720.txt\n",
      "downloads/190727.txt\n",
      "downloads/190803.txt\n",
      "downloads/190810.txt\n",
      "downloads/190817.txt\n",
      "downloads/190824.txt\n",
      "downloads/190831.txt\n",
      "downloads/190907.txt\n",
      "downloads/190914.txt\n",
      "downloads/190921.txt\n",
      "downloads/190928.txt\n",
      "downloads/191005.txt\n",
      "downloads/191012.txt\n",
      "downloads/191019.txt\n",
      "downloads/191026.txt\n",
      "downloads/191102.txt\n",
      "downloads/191109.txt\n",
      "downloads/191116.txt\n",
      "downloads/191123.txt\n",
      "downloads/191130.txt\n",
      "downloads/191207.txt\n",
      "downloads/191214.txt\n",
      "downloads/191221.txt\n",
      "downloads/191228.txt\n",
      "downloads/200104.txt\n",
      "downloads/200111.txt\n",
      "downloads/200118.txt\n",
      "downloads/200125.txt\n",
      "downloads/200201.txt\n",
      "downloads/200208.txt\n",
      "downloads/200215.txt\n",
      "downloads/200222.txt\n",
      "downloads/200229.txt\n",
      "downloads/200307.txt\n",
      "downloads/200314.txt\n",
      "downloads/200321.txt\n",
      "downloads/200328.txt\n",
      "downloads/200404.txt\n",
      "downloads/200411.txt\n",
      "downloads/200418.txt\n",
      "downloads/200425.txt\n",
      "downloads/200502.txt\n",
      "downloads/200509.txt\n",
      "downloads/200516.txt\n",
      "downloads/200523.txt\n",
      "downloads/200530.txt\n",
      "downloads/200606.txt\n",
      "downloads/200613.txt\n",
      "downloads/200620.txt\n",
      "downloads/200627.txt\n",
      "downloads/200704.txt\n",
      "downloads/200711.txt\n",
      "downloads/200718.txt\n",
      "downloads/200725.txt\n",
      "downloads/200801.txt\n",
      "downloads/200808.txt\n",
      "downloads/200815.txt\n",
      "downloads/200822.txt\n",
      "downloads/200829.txt\n",
      "downloads/200905.txt\n",
      "downloads/200912.txt\n",
      "downloads/200919.txt\n",
      "downloads/200926.txt\n",
      "downloads/201003.txt\n",
      "downloads/201010.txt\n",
      "downloads/201017.txt\n",
      "downloads/201024.txt\n",
      "downloads/201031.txt\n",
      "downloads/201107.txt\n",
      "downloads/201114.txt\n",
      "downloads/201121.txt\n",
      "downloads/201128.txt\n",
      "downloads/201205.txt\n",
      "downloads/201212.txt\n",
      "downloads/201219.txt\n",
      "downloads/201226.txt\n",
      "downloads/210102.txt\n",
      "downloads/210109.txt\n",
      "downloads/210116.txt\n",
      "downloads/210123.txt\n",
      "downloads/210130.txt\n",
      "downloads/210206.txt\n",
      "downloads/210213.txt\n",
      "downloads/210220.txt\n",
      "downloads/210227.txt\n",
      "downloads/210306.txt\n",
      "downloads/210313.txt\n",
      "downloads/210320.txt\n",
      "downloads/210327.txt\n",
      "downloads/210403.txt\n",
      "downloads/210410.txt\n",
      "downloads/210417.txt\n",
      "downloads/210424.txt\n",
      "downloads/210501.txt\n",
      "downloads/210508.txt\n",
      "downloads/210515.txt\n",
      "downloads/210522.txt\n",
      "downloads/210529.txt\n",
      "downloads/210605.txt\n",
      "downloads/210612.txt\n",
      "downloads/210619.txt\n",
      "downloads/210626.txt\n",
      "downloads/210703.txt\n",
      "downloads/210710.txt\n",
      "downloads/210717.txt\n",
      "downloads/210724.txt\n",
      "downloads/210731.txt\n",
      "downloads/210807.txt\n",
      "downloads/210814.txt\n",
      "downloads/210821.txt\n",
      "downloads/210828.txt\n",
      "downloads/210904.txt\n",
      "downloads/210911.txt\n",
      "downloads/210918.txt\n",
      "downloads/210925.txt\n",
      "downloads/211002.txt\n",
      "downloads/211009.txt\n",
      "downloads/211016.txt\n",
      "downloads/211023.txt\n",
      "downloads/211030.txt\n",
      "downloads/211106.txt\n",
      "downloads/211113.txt\n",
      "downloads/211120.txt\n",
      "downloads/211127.txt\n",
      "downloads/211204.txt\n",
      "downloads/211211.txt\n",
      "downloads/211218.txt\n",
      "downloads/211225.txt\n",
      "downloads/220101.txt\n",
      "downloads/220108.txt\n",
      "downloads/220115.txt\n",
      "downloads/220122.txt\n",
      "downloads/220129.txt\n",
      "downloads/220205.txt\n",
      "downloads/220212.txt\n",
      "downloads/220219.txt\n",
      "downloads/220226.txt\n",
      "downloads/220305.txt\n",
      "downloads/220312.txt\n",
      "downloads/220319.txt\n",
      "downloads/220326.txt\n",
      "downloads/220402.txt\n",
      "downloads/220409.txt\n",
      "downloads/220416.txt\n",
      "downloads/220423.txt\n",
      "downloads/220430.txt\n",
      "downloads/220507.txt\n",
      "downloads/220514.txt\n",
      "downloads/220521.txt\n",
      "downloads/220528.txt\n",
      "downloads/220604.txt\n",
      "downloads/220611.txt\n",
      "downloads/220618.txt\n",
      "downloads/220625.txt\n",
      "downloads/220702.txt\n",
      "downloads/220709.txt\n",
      "downloads/220716.txt\n",
      "downloads/220723.txt\n",
      "downloads/220730.txt\n",
      "downloads/220806.txt\n",
      "downloads/220813.txt\n",
      "downloads/220820.txt\n",
      "downloads/220827.txt\n",
      "downloads/220903.txt\n",
      "downloads/220910.txt\n",
      "downloads/220917.txt\n",
      "downloads/220924.txt\n",
      "downloads/221001.txt\n",
      "downloads/221008.txt\n",
      "downloads/221015.txt\n",
      "downloads/221022.txt\n",
      "downloads/221029.txt\n",
      "downloads/221105.txt\n",
      "downloads/221112.txt\n",
      "downloads/221119.txt\n",
      "downloads/221126.txt\n",
      "downloads/221203.txt\n",
      "downloads/221210.txt\n",
      "downloads/221217.txt\n",
      "downloads/221224.txt\n",
      "downloads/221231.txt\n"
     ]
    }
   ],
   "source": [
    "datadir = \"downloads\"\n",
    "datafiles = sorted([datadir + \"/\" + f for f in listdir(datadir) if f[-4:]==\".txt\"])\n",
    "\n",
    "for f in datafiles:\n",
    "    print (\"%s Loading %s\" % (strftime(\"%H:%M:%S\"), f))\n",
    "    %sql insert into temp_data SELECT * FROM read_csv(:f, \\\n",
    "                                                      delim=',', \\\n",
    "                                                      header=True, \\\n",
    "                                                      columns={'C/A': 'VARCHAR', \\\n",
    "                                                               'UNIT': 'VARCHAR', \\\n",
    "                                                               'SCP': 'VARCHAR', \\\n",
    "                                                               'STATION': 'VARCHAR', \\\n",
    "                                                               'LINENAME': 'VARCHAR', \\\n",
    "                                                               'DIVISION': 'VARCHAR', \\\n",
    "                                                               'DATE': 'DATE', \\\n",
    "                                                               'TIME': 'TIME',\\\n",
    "                                                               'DESC': 'VARCHAR',\\\n",
    "                                                               'ENTRIES': 'INTEGER',\\\n",
    "                                                               'EXITS': 'INTEGER',},\\\n",
    "                                                      dateformat='%m/%d/%Y');\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43361148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0      43361148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 header row in each file\n",
    "# subtract number of files from number of lines found by wc above, should equal this number\n",
    "\n",
    "%sql SELECT COUNT(*) FROM temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from temp_data limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43150216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0      43150216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deduplicate rows\n",
    "%sql create table mta as SELECT distinct * FROM \"temp_data\" ;\n",
    "%sql drop table temp_data;\n",
    "%sql SELECT COUNT(*) FROM mta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42956693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0      42956693"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove these audit records ... might need to check if they should always be deleted\n",
    "%sql delete from mta where \"DESC\" = 'RECOVR AUD';\n",
    "%sql SELECT COUNT(*) FROM mta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42956693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "0  42956693"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add timestamp from date/time\n",
    "%sql alter table mta add column DATE_TIME timestamp;\n",
    "%sql update mta set DATE_TIME = make_timestamp(date_part('year', date), date_part('month', date), date_part('day', date),date_part('hour', TIME), date_part('minute', TIME), date_part('second', TIME))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42956693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "0  42956693"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make unique turnstile labels\n",
    "%sql alter table mta add column TURNSTILE VARCHAR;\n",
    "%sql update mta set TURNSTILE = CONCAT(\"C/A\" , ' ' , UNIT , ' ' , SCP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make unique station names, else you have '7 AV' in Manhattan, Brooklyn, multiple \"23 St\" etc\n",
    "%sql update mta set station = concat(station, '-', linename);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ST-UNION SQ-LNQR456W -> 14 ST-UNION SQ-456LNQRW\n",
      "161/YANKEE STAD-BD4 -> 161/YANKEE STAD-4BD\n",
      "34 ST-PENN STA-123 -> 34 ST-PENN STA-123ACE\n",
      "34 ST-PENN STA-ACE -> 34 ST-PENN STA-123ACE\n",
      "42 ST-PORT AUTH-ACENGRS1237W -> 42 ST-PORT AUTH-ACENQRS1237W\n",
      "59 ST-NQR456W -> 59 ST-456NQRW\n",
      "59 ST-NRW -> 59 ST-456NQRW\n",
      "59 ST COLUMBUS-ABCD1 -> 59 ST COLUMBUS-1ABCD\n",
      "ATL AV-BARCLAY-BDNQR2345 -> ATL AV-BARCLAY-2345BDNQR\n",
      "BOROUGH HALL-R2345 -> BOROUGH HALL-2345R\n",
      "COURT SQ-23 ST-EMG -> COURT SQ-EMG\n",
      "FULTON ST-ACJZ2345 -> FULTON ST-2345ACJZ\n",
      "GUN HILL RD-5 -> GUN HILL RD-25\n",
      "PATH WTC 2-PTH-1 -> PATH NEW WTC-PTH-1\n",
      "PELHAM PKWY-5 -> PELHAM PKWY-25\n"
     ]
    }
   ],
   "source": [
    "# fix some issues with same station having multiple names\n",
    "# in ideal world would cross-reference MTA station list\n",
    "fixes = {\n",
    "    '14 ST-UNION SQ-LNQR456W': '14 ST-UNION SQ-456LNQRW',\n",
    "    '161/YANKEE STAD-BD4': '161/YANKEE STAD-4BD',\n",
    "    '34 ST-PENN STA-123': '34 ST-PENN STA-123ACE',\n",
    "    '34 ST-PENN STA-ACE': '34 ST-PENN STA-123ACE',\n",
    "    '42 ST-PORT AUTH-ACENGRS1237W': '42 ST-PORT AUTH-ACENQRS1237W',\n",
    "    '59 ST-NQR456W': '59 ST-456NQRW',\n",
    "    '59 ST-NRW': '59 ST-456NQRW',\n",
    "    '59 ST COLUMBUS-ABCD1': '59 ST COLUMBUS-1ABCD',\n",
    "    'ATL AV-BARCLAY-BDNQR2345': 'ATL AV-BARCLAY-2345BDNQR',\n",
    "    'BOROUGH HALL-R2345': 'BOROUGH HALL-2345R',\n",
    "    'COURT SQ-23 ST-EMG': 'COURT SQ-EMG',\n",
    "    'FULTON ST-ACJZ2345': 'FULTON ST-2345ACJZ',\n",
    "    'GUN HILL RD-5': 'GUN HILL RD-25',\n",
    "    'PATH WTC 2-PTH-1': 'PATH NEW WTC-PTH-1',\n",
    "    'PELHAM PKWY-5': 'PELHAM PKWY-25',\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in fixes.items():\n",
    "    print(k, '->', v)\n",
    "    %sql update mta set station = :v where station = :k;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT station, count(*) FROM mta group by station order by station;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure why %sql magic sometimes doesn't work here  \n",
    "con = duckdb.connect('mta.db')\n",
    "query = \"SELECT station, count(*) FROM mta group by station order by station;\"\n",
    "con.execute(query)\n",
    "con.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE mta DROP LINENAME;\n",
    "ALTER TABLE mta DROP DIVISION;\n",
    "ALTER TABLE mta DROP \"DESC\";\n",
    "ALTER TABLE mta DROP TIME;\n",
    "ALTER TABLE mta DROP \"C/A\";\n",
    "ALTER TABLE mta DROP UNIT;\n",
    "ALTER TABLE mta DROP SCP;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PRAGMA database_size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"PRAGMA database_size;\"\n",
    "# con.execute(query)\n",
    "# con.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Ending DuckDB initial load\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data quality with DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if each turnstile is available for each station for each time, compute % time coverage vs. expected\n",
    "- check any overlapping time periods by turnstile \n",
    "- compute change in entries, exits by turnstile by time\n",
    "- fix negatives\n",
    "- fix outliers, usually indicate maintenance reset count \n",
    "\n",
    "Should review articles and Todd Schneider code for additional data quality checks and fixes. Could possibly add better data quality with\n",
    "\n",
    "- https://greatexpectations.io/\n",
    "- https://pandera.readthedocs.io/en/stable/\n",
    "- https://github.com/awslabs/python-deequ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Starting diff and DQ\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists mta_diff;\n",
    "\n",
    "CREATE TABLE mta_diff AS \n",
    "SELECT DATE, DATE_TIME, STATION, TURNSTILE, \n",
    "ENTRY_COUNTER,\n",
    "ENTRY_COUNTER - lag(ENTRY_COUNTER) OVER (PARTITION BY STATION, TURNSTILE ORDER BY DATE_TIME) AS ENTRIES,\n",
    "2000 ENTRIES_CUTOFF ,\n",
    "EXIT_COUNTER,\n",
    "EXIT_COUNTER - lag(EXIT_COUNTER) OVER (PARTITION BY STATION, TURNSTILE ORDER BY DATE_TIME) AS EXITS,\n",
    "2000 EXITS_CUTOFF\n",
    "FROM mta;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql describe mta_diff;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from mta_diff order by station, turnstile, date_time limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql drop table mta;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE mta_diff drop column ENTRY_COUNTER;\n",
    "%sql ALTER TABLE mta_diff drop column EXIT_COUNTER;\n",
    "%sql ALTER TABLE mta_diff RENAME TO mta;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select DATE_TIME, STATION, TURNSTILE, count(*) from mta\n",
    "group by DATE_TIME, STATION, TURNSTILE\n",
    "having count(*) > 1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fix <=0, sometimes maintenance is done, resets turnstile counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows at start of window with no diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta\n",
    "where entries is null \n",
    "and exits is null;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where ENTRIES < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where EXITS < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where ENTRIES < 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where EXITS < 0;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping bad rows\n",
    "\n",
    "- Taking a slightly more permissive approach than cutting off everything > 2K\n",
    "- Looking at e.g. BEDFORD AV-L\tH009\tR235\t00-03-04 , does 2000 on the regular\n",
    "- First cut off everything > 6K. Every 2s = 7200 in 4h period. but I wonder if sometimes the period is longer? I could see a deal at a massive event where trains keep coming and there is always a queue at a turnstile\n",
    "- Then compute average, sd, count by turnstile\n",
    "- if count < 20 then cut off everything > 2K\n",
    "- if count >= 20 then cut off everything based on SD, with a 1K minmimum threshold\n",
    "- Seems to call for some kind of bayesian approach, maybe use one of the DQ packages\n",
    "    - for each new turnstile start with a prior distribution on the turnstile mean and sd based on all the turnstiles\n",
    "    - for each observation at that turnstile, update the prior\n",
    "    - at the end , discard the observations that are eg 4 updated sds from the updated mean. (we should think about what sort of true distribution there is, how many we will discard, what the tradeoff is for rejecting a row incorrectly).\n",
    "    - so if you only have 1 observation, you'll be discarding based on close to the population mean and sd\n",
    "    - if you have 30 observations, you'll be discarding based on close to the turnstile mean and sd\n",
    "    - also if there was turnstile maintenance both entries and exits should be off, can add signal and reduce sd threshold and require both to be off (not doing this)\n",
    "     - IMO it's pretty easy for something weird to happen where something goes to a different mode, flood or cops or something closes an entrance, 1-time big event. Seems like a good DQ framework needs a flexible rule plus some whitelisted days/exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard 7200 limit per turnstile per period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where ENTRIES > 7200;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta where EXITS > 7200;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where ENTRIES>7200;\n",
    "delete from mta where EXITS>7200;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average, sd, observation count by turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists entry_avg;\n",
    "create table entry_avg as \n",
    "select station, TURNSTILE, avg(entries) MEAN, stddev(entries) SD, count(*) N, \n",
    "from mta\n",
    "where entries > 0\n",
    "group by station, TURNSTILE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select * from entry_avg order by MEAN desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from entry_avg where turnstile ='N078 R175 01-06-00'\n",
    "limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from mta\n",
    "where turnstile ='N078 R175 01-06-00'\n",
    "order by entries desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table entry_avg add column ENTRIES_CUTOFF DOUBLE;\n",
    "update entry_avg set ENTRIES_CUTOFF = MEAN + 3 * SD;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where N <= 20;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where ENTRIES_CUTOFF > 100000;\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where isnan(ENTRIES_CUTOFF);\n",
    "update entry_avg set ENTRIES_CUTOFF = 2000 where ENTRIES_CUTOFF < 2000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "update mta \n",
    "set ENTRIES_CUTOFF = (\n",
    "select ENTRIES_CUTOFF from entry_avg\n",
    "    where\n",
    "    entry_avg.station = mta.station and \n",
    "    entry_avg.turnstile = mta.turnstile\n",
    ")\n",
    "where exists (\n",
    "    select 1 from entry_avg\n",
    "    where\n",
    "    entry_avg.station = mta.station and \n",
    "    entry_avg.turnstile = mta.turnstile\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists exit_avg;\n",
    "create table exit_avg as \n",
    "select station, TURNSTILE, avg(exits) MEAN, stddev(exits) SD, count(*) N, \n",
    "from mta\n",
    "where exits > 0\n",
    "group by station, TURNSTILE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from exit_avg order by MEAN desc limit 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from mta where turnstile='N012 R035 01-05-01'\n",
    "order by exits desc limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table exit_avg add column EXITS_CUTOFF DOUBLE;\n",
    "update exit_avg set EXITS_CUTOFF = MEAN + 3 * SD;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where N <= 20;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where EXITS_CUTOFF > 100000;\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where isnan(EXITS_CUTOFF);\n",
    "update exit_avg set EXITS_CUTOFF = 2000 where EXITS_CUTOFF < 2000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "update mta\n",
    "set EXITS_CUTOFF = (\n",
    "select EXITS_CUTOFF from exit_avg\n",
    "    where\n",
    "    exit_avg.station = mta.station and \n",
    "    exit_avg.turnstile = mta.turnstile \n",
    ")\n",
    "where exists (\n",
    "    select 1 from exit_avg\n",
    "    where\n",
    "    exit_avg.station = mta.station and \n",
    "    exit_avg.turnstile = mta.turnstile\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s deleting based on cutoff\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard cutoff, delete if either exits or entries exceeds. \n",
    "# although if a technical issue both entries and exits should be off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "delete from mta where entries > entries_cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where exits > exits_cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "delete from mta where entries=0 and exits=0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Finishing diff and DQ\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "describe mta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PRAGMA database_size;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s Starting aggregation and dataviz\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "df << select DATE, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "group by date\n",
    "order by date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"rolling\"] = df['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"DATE\"], df[\"rolling\"])\n",
    "plt.title(\"NYC Subway Entries - All, 7-day Moving Average\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_stations = ['1 AV-L',\n",
    "'14 ST-123FLM',\n",
    "'14 ST-ACEL',\n",
    "'14 ST-UNION SQ-456LNQRW',\n",
    "'14TH STREET-1',\n",
    "'18 ST-1',\n",
    "'2 AV-F',\n",
    "'23 ST-1',\n",
    "'23 ST-6',\n",
    "'23 ST-CE',\n",
    "'23 ST-FM',\n",
    "'23 ST-NRW',\n",
    "'28 ST-1',\n",
    "'28 ST-6',\n",
    "'28 ST-NRW',\n",
    "'3 AV-L',\n",
    "'33 ST-6',\n",
    "'34 ST-HERALD SQ-BDFMNQRW',\n",
    "'34 ST-HUDSON YD-7',\n",
    "'34 ST-PENN STA-123',\n",
    "'34 ST-PENN STA-123ACE',\n",
    "'34 ST-PENN STA-ACE',\n",
    "'42 ST-BRYANT PK-7BDFM',\n",
    "'42 ST-PORT AUTH-1237ACEGNRSW',\n",
    "'42 ST-PORT AUTH-1237ACENQRSW',\n",
    "'47-50 STS ROCK-BDFM',\n",
    "'49 ST-NQRW',\n",
    "'5 AV/53 ST-EM',\n",
    "'5 AV/59 ST-NQRW',\n",
    "'5 AVE-7BDFM',\n",
    "'50 ST-1',\n",
    "'50 ST-CE',\n",
    "'50 ST-D',\n",
    "'51 ST-6',\n",
    "'57 ST-7 AV-NQRW',\n",
    "'57 ST-F',\n",
    "'59 ST COLUMBUS-1ABCD',\n",
    "'59 ST-456NQRW',\n",
    "'59 ST-NRW',\n",
    "'6 AV-123FLM',\n",
    "'7 AV-BDE',\n",
    "'8 AV-ACEL',\n",
    "'8 ST-NYU-NRW',\n",
    "'9TH STREET-1',\n",
    "'ASTOR PL-6',\n",
    "\"B'WAY-LAFAYETTE-6BDFQ\",\n",
    "'BLEECKER ST-6DF',\n",
    "'BOWLING GREEN-45',\n",
    "'BROAD ST-JZ',\n",
    "'BROOKLYN BRIDGE-456JZ',\n",
    "'CANAL ST-1',\n",
    "'CANAL ST-6JNQRWZ',\n",
    "'CANAL ST-ACE',\n",
    "'CHAMBERS ST-123',\n",
    "'CHAMBERS ST-23ACE',\n",
    "'CHAMBERS ST-456JZ',\n",
    "'CHRISTOPHER ST-1',\n",
    "'CITY HALL-NRW',\n",
    "'CORTLANDT ST-NRW',\n",
    "'DELANCEY/ESSEX-FJMZ',\n",
    "'EAST BROADWAY-F',\n",
    "'EXCHANGE PLACE-1',\n",
    "'FRANKLIN ST-1',\n",
    "'FULTON ST-2345ACJZ',\n",
    "'GRAND ST-BD',\n",
    "'GRD CNTRL-42 ST-4567S',\n",
    "'HOUSTON ST-1',\n",
    "'LEXINGTON AV/53-6EM',\n",
    "'LEXINGTON AV/63-F',\n",
    "'PARK PLACE-23ACE',\n",
    "'PATH NEW WTC-1',\n",
    "'PATH WTC 2-1',\n",
    "'PRINCE ST-NRW',\n",
    "'RECTOR ST-1',\n",
    "'RECTOR ST-NRW',\n",
    "'SOUTH FERRY-1RW',\n",
    "'SPRING ST-6',\n",
    "'SPRING ST-CE',\n",
    "'TIMES SQ-42 ST-1237ACENQRS',\n",
    "'TIMES SQ-42 ST-1237ACENQRSW',\n",
    "'TWENTY THIRD ST-1',\n",
    "'W 4 ST-WASH SQ-ABCDEFM',\n",
    "'WALL ST-23',\n",
    "'WALL ST-45',\n",
    "'WHITEHALL S-FRY-1RW',\n",
    "'WORLD TRADE CTR-23ACE',\n",
    "'WTC-CORTLANDT-1',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql df << select DATE, STATION, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "group by DATE, STATION\n",
    "order by entries desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhattan < 66 st\n",
    "# before 11am on weekday\n",
    "cbd_df = df.loc[df[\"STATION\"].isin(cbd_stations)].copy()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df = cbd_df[['DATE', 'ENTRIES']].groupby(\"DATE\") \\\n",
    "    .sum() \\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df[\"rolling\"] = cbd_df['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "\n",
    "plt.plot(cbd_df[\"DATE\"], cbd_df[\"rolling\"])\n",
    "plt.title(\"NYC Subway Entries - CBD, 7-day Moving Average\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "df << select DATE, DATE_TIME, sum(ENTRIES) ENTRIES\n",
    "from mta\n",
    "where ENTRIES > 0\n",
    "group by DATE, DATE_TIME\n",
    "order by DATE, DATE_TIME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df[\"DATE_TIME\"].dt.weekday\n",
    "df[\"hour\"] = df[\"DATE_TIME\"].dt.hour\n",
    "\n",
    "morn_df = df.loc[df[\"weekday\"] < 5]\n",
    "df_am = morn_df.loc[df[\"hour\"] < 12]\n",
    "df_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ent = df_am[[\"DATE\", \"ENTRIES\"]] \\\n",
    "    .groupby([\"DATE\"]) \\\n",
    "    .sum() \\\n",
    "    .reset_index() \\\n",
    "    .copy()\n",
    "\n",
    "agg_ent[\"rolling\"] = agg_ent['ENTRIES'].rolling(7).sum()/7/1000000\n",
    "agg_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agg_ent[\"DATE\"], agg_ent[\"rolling\"])\n",
    "plt.title(\"Entries - Weekday Mornings\")\n",
    "plt.gcf().autofmt_xdate();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationmap = {'1 AV - L': '1st Ave - L',\n",
    " '103 ST - 1': '103rd St - 1',\n",
    " '103 ST - 6': '103rd St - 4-6-6 Express',\n",
    " '103 ST - BC': '103rd St - A-B-C',\n",
    " '103 ST-CORONA - 7': '103rd St - Corona Plaza - 7',\n",
    " '104 ST - A': '104th St - A-S',\n",
    " '104 ST - JZ': '104th-102nd Sts - J-Z',\n",
    " '110 ST - 6': '110th St - 4-6-6 Express',\n",
    " '111 ST - 7': '111th St - 7',\n",
    " '111 ST - A': '111th St - A-S',\n",
    " '111 ST - J': '111th St - J',\n",
    " '116 ST - 23': '116th St - 2-3',\n",
    " '116 ST - 6': '116th St - 4-6-6 Express',\n",
    " '116 ST - BC': '116th St - A-B-C',\n",
    " '116 ST-COLUMBIA - 1': '116th St - Columbia University - 1',\n",
    " '121 ST - JZ': '121st St - J-Z',\n",
    " '125 ST - 1': '125th St - 1',\n",
    " '125 ST - 23': '125th St - 2-3',\n",
    " '125 ST - 456': '125th St - 4-5-6-6 Express',\n",
    " '125 ST - ACBD': '125th St - A-B-C-D',\n",
    " '135 ST - 23': '135th St - 2-3',\n",
    " '135 ST - BC': '135th St - A-B-C',\n",
    " '137 ST CITY COL - 1': '137th St - City College - 1',\n",
    " '138/GRAND CONC - 45': '138th St - Grand Concourse - 4-5',\n",
    " '14 ST - 123FLM': '14th St - F-M',\n",
    " '14 ST - ACEL': '14th St - A-C-E',\n",
    " '14 ST - FLM123': '14th St - F-M',\n",
    " '14 ST-UNION SQ - 456LNQRW': 'Union Sq - 14th St - 4-5-6-6 Express',\n",
    " '14 ST-UNION SQ - LNQR456W': 'Union Sq - 14th St - N-Q-R-W',\n",
    " '145 ST - 1': '145th St - 1',\n",
    " '145 ST - ABCD': '145th St - A-B-C-D',\n",
    " '149/GRAND CONC - 245': '149th St - Grand Concourse - 2-5',\n",
    " '14TH STREET - 1': '14th St - 1-2-3',\n",
    " '15 ST-PROSPECT - FG': '15th St - Prospect Park - F-G',\n",
    " '155 ST - BD': '155th St - B-D',\n",
    " '155th St - A-C': '155 ST - C',\n",
    " '155 ST - C': '155th St - A-C',\n",
    " '157 ST - 1': '157th St - 1',\n",
    " '161/YANKEE STAD - 4BD': '161st St - Yankee Stadium - 4',\n",
    " '161/YANKEE STAD - BD4': '161st St - Yankee Stadium - 4',\n",
    " '167 ST - 4': '167th St - 4',\n",
    " '168 ST - 1AC': '168th St - 1',\n",
    " '168 ST - AC1': '168th St - 1',\n",
    " '169 ST - F': '169th St - F',\n",
    " '170 ST - 4': '170th St - 4',\n",
    " '170 ST - BD': '170th St - B-D',\n",
    " '174 ST - 25': '174th St - 2-5',\n",
    " '175 ST - A': '175th St - A',\n",
    " '176 ST - 4': '176th St - 4',\n",
    " '18 AV - D': '18th Ave - D',\n",
    " '18 AV - F': '18th Ave - F',\n",
    " '18 AV - N': '18th Ave - N',\n",
    " '18 ST - 1': '18th St - 1-2',\n",
    " '181 ST - 1': '181st St - 1',\n",
    " '181 ST - A': '181st St - A',\n",
    " '182-183 STS - BD': '182nd-183rd Sts - B-D',\n",
    " '183 ST - 4': '183rd St - 4',\n",
    " '190 ST - A': '190th St - A',\n",
    " '191 ST - 1': '191st St - 1',\n",
    " '2 AV - F': 'Lower East Side - 2nd Ave - F',\n",
    " '20 AV - D': '20th Ave - D',\n",
    " '20 AV - N': '20th Ave - N',\n",
    " '207 ST - 1': '207th St - 1',\n",
    " '21 ST - G': '21st St - G',\n",
    " '21 ST-QNSBRIDGE - F': '21st St - Queensbridge - F',\n",
    " '215 ST - 1': '215th St - 1',\n",
    " '219 ST - 25': '219th St - 2-5',\n",
    " '225 ST - 25': '225th St - 2-5',\n",
    " '23 ST - 1': '23rd St - 1-2',\n",
    " '23 ST - 6': '23rd St - 4-6-6 Express',\n",
    " '23 ST - CE': '23rd St - A-C-E',\n",
    " '23 ST - NRW': '23rd St - N-Q-R-W',\n",
    " '231 ST - 1': '231st St - 1',\n",
    " '233 ST - 25': '233rd St - 2-5',\n",
    " '238 ST - 1': '238th St - 1',\n",
    " '25 AV - D': '25th Ave - D',\n",
    " '25 ST - R': '25th St - D-N-R',\n",
    " '28 ST - 1': '28th St - 1-2',\n",
    " '28 ST - NRW': '28th St - N-Q-R-W',\n",
    " '3 AV - L': '3rd Ave - L',\n",
    " '3 AV 138 ST - 6': '3rd Ave - 138th St - 6-6 Express',\n",
    " '3 AV-149 ST - 25': '3rd Ave - 149th St - 2-5',\n",
    " '30 AV - NQW': '30th Ave - N-W',\n",
    " '33 ST - 6': '33rd St - 4-6-6 Express',\n",
    " '33 ST-RAWSON ST - 7': '33rd St - 7',\n",
    " '34 ST-HERALD SQ - BDFMNQRW': 'Herald Sq - 34th St - B-D-F-M',\n",
    " '34 ST-HUDSON YD - 7': '34th St - Hudson Yards - 7-7 Express',\n",
    " '34 ST-PENN STA - 123': '34th St - Penn Station - 1-2-3',\n",
    " '34 ST-PENN STA - 123ACE': '34th St - Penn Station - A-C-E',\n",
    " '34 ST-PENN STA - ACE': '34th St - Penn Station - A-C-E',\n",
    " '36 AV - NQW': '36th Ave - N-W',\n",
    " '36 ST - DNR': '36th St - D-N-R',\n",
    " '36 ST - MR': '36th St - E-M-R',\n",
    " '4 AV-9 ST - DFGMNR': '4th Av - 9th St - D-N-R',\n",
    " '40 ST LOWERY ST - 7': '40th St - 7',\n",
    " '42 ST-BRYANT PK - BDFM7': '42nd St - Bryant Pk - B-D-F-M',\n",
    " '42 ST-PORT AUTH - ACENGRS1237W': '42nd St - Port Authority Bus Term - A-C-E',\n",
    " '42 ST-PORT AUTH - ACENQRS1237W': '42nd St - Port Authority Bus Term - A-C-E',\n",
    " '45 ST - R': '45th St - N-R',\n",
    " '46 ST - MR': '46th St - E-M-R',\n",
    " '46 ST BLISS ST - 7': '46th St - 7',\n",
    " '47-50 STS ROCK - BDFM': '47th-50th Sts - Rockefeller Ctr - B-D-F-M',\n",
    " '49 ST - NQRW': '49th St - N-Q-R-W',\n",
    " '4AV-9 ST - DFGMNR': '4th Av - 9th St - D-N-R',\n",
    " '5 AV/53 ST - EM': '5th Ave - 53rd St - E-M',\n",
    " '5 AV/59 ST - NQRW': '5th Ave - 59th St - N-R-W',\n",
    " '5 AVE - 7BDFM': '5th Ave - Bryant Pk - 7-7 Express',\n",
    " '50 ST - 1': '50th St - 1-2',\n",
    " '50 ST - CE': '50th St - A-C-E',\n",
    " '50 ST - D': '50th St - D',\n",
    " '51 ST - 6': '51st St - 4-6-6 Express',\n",
    " '52 ST - 7': '52nd St - 7',\n",
    " '53 ST - R': '53rd St - N-R',\n",
    " '55 ST - D': '55th St - D',\n",
    " '57 ST-7 AV - NQRW': '57th St - N-Q-R-W',\n",
    " '59 ST - 456NQRW': 'Lexington Ave - 59th St - 4-5-6-6 Express',\n",
    " '59 ST - NQR456W': '59th St - N-R',\n",
    " '59 ST - NRW': '59th St - N-R',\n",
    " '59 ST COLUMBUS - 1ABCD': '59th St - Columbus Circle - 1-2',\n",
    " '59 ST COLUMBUS - ABCD1': '59th St - Columbus Circle - A-B-C-D',\n",
    " '6 AV - FLM123': '6th Ave - L',\n",
    " '61 ST WOODSIDE - 7': 'Woodside - 61st St - 7-7 Express',\n",
    " '63 DR-REGO PARK - MR': '63rd Dr - Rego Park - E-M-R',\n",
    " '65 ST - MR': '65th St - E-M-R',\n",
    " '66 ST-LINCOLN - 1': '66th St - Lincoln Ctr - 1-2',\n",
    " '67 AV - MR': '67th Ave - E-M-R',\n",
    " '68ST-HUNTER CO - 6': '68th St - Hunter College - 4-6-6 Express',\n",
    " '69 ST - 7': '69th St - 7',\n",
    " '7 AV - BDE': '7th Ave - B-D-E',\n",
    " '7 AV - BQ': '7th Ave - B-Q',\n",
    " '7 AV - FG': '7th Ave - F-G',\n",
    " '71 ST - D': '71st St - D',\n",
    " '72 ST - 123': '72nd St - 1-2-3',\n",
    " '72 ST-2 AVE - Q': '72nd St - Q',\n",
    " '74 ST-BROADWAY - 7EFMR': '74th St - Broadway - 7',\n",
    " '75 AV - EF': '75th Ave - E-F',\n",
    " '75 ST-ELDERTS - JZ': '75th St - Eldert Ln - J-Z',\n",
    " '77 ST - 6': '77th St - 4-6-6 Express',\n",
    " '77 ST - R': '77th St - R',\n",
    " '79 ST - 1': '79th St - 1-2',\n",
    " '79 ST - D': '79th St - D',\n",
    " '8 AV - ACEL': '8th Ave - L',\n",
    " '8 AV - N': '8th St - NYU - N-Q-R-W',\n",
    " '8 ST-NYU - NRW': '8th St - NYU - N-Q-R-W',\n",
    " '80 ST - A': '80th St - A-S',\n",
    " '81 ST-MUSEUM - BC': '81st St - A-B-C',\n",
    " '82 ST-JACKSON H - 7': '82nd St - Jackson Hts - 7',\n",
    " '85 ST-FOREST PK - J': '85th St - Forest Pky - J',\n",
    " '86 ST - 1': '86th St - 1-2',\n",
    " '86 ST - 456': '86th St - 4-5-6-6 Express',\n",
    " '86 ST - N': '86th St - R',\n",
    " '86 ST - R': '86th St - R',\n",
    " '86 ST-2 AVE - Q': '86th St - Q',\n",
    " '88 ST - A': '88th St - A-S',\n",
    " '9 AV - D': '9th Ave - D',\n",
    " '90 ST-ELMHURST - 7': '90th St - Elmhurst Av - 7',\n",
    " '96 ST - 123': '96th St - 1-2-3',\n",
    " '96 ST - 6': '96th St - 4-6-6 Express',\n",
    " '96 ST - BC': '96th St - A-B-C',\n",
    " '96 ST-2 AVE - Q': '96th St - Q',\n",
    " 'ALABAMA AV - J': 'Alabama Ave - J',\n",
    " 'ALLERTON AV - 25': 'Allerton Ave - 2-5',\n",
    " 'AQUEDUCT N.COND - A': 'Aqueduct - North Conduit Av - A',\n",
    " 'AQUEDUCT RACETR - A': 'Aqueduct Racetrack - A',\n",
    " 'ASTOR PL - 6': 'Astor Pl - 4-6-6 Express',\n",
    " 'ASTORIA BLVD - NQW': 'Astoria Blvd - N-W',\n",
    " 'ASTORIA DITMARS - NQW': 'Astoria - Ditmars Blvd - N-W',\n",
    " 'ATL AV-BARCLAY - 2345BDNQR': \"Atlantic Av - Barclay's Center - 2-3-4-5\",\n",
    " 'ATL AV-BARCLAY - BDNQR2345': \"Atlantic Av - Barclay's Center - B-Q\",\n",
    " 'ATLANTIC AV - L': 'Atlantic Ave - L',\n",
    " 'AVENUE H - BQ': 'Ave H - Q',\n",
    " 'AVENUE I - F': 'Ave I - F',\n",
    " 'AVENUE J - BQ': 'Ave J - Q',\n",
    " 'AVENUE M - BQ': 'Ave M - Q',\n",
    " 'AVENUE N - F': 'Ave N - F',\n",
    " 'AVENUE P - F': 'Ave P - F',\n",
    " 'AVENUE U - BQ': 'Ave U - Q',\n",
    " 'AVENUE U - F': 'Ave U - F',\n",
    " 'AVENUE U - N': 'Ave U - N',\n",
    " 'AVENUE X - F': 'Ave X - F',\n",
    " \"B'WAY-LAFAYETTE - BDFQ6\": 'Broadway - Lafayette St - B-D-F-M',\n",
    " 'BAY 50 ST - D': 'Bay 50th St - D',\n",
    " 'BAY PKWY - D': 'Bay Pky - D',\n",
    " 'BAY PKWY - F': 'Bay Pky - F',\n",
    " 'BAY PKWY - N': 'Bay Pky - N',\n",
    " 'BAY RIDGE AV - R': 'Bay Ridge Ave - R',\n",
    " 'BAY RIDGE-95 ST - R': 'Bay Ridge - 95th St - R',\n",
    " 'BAYCHESTER AV - 5': 'Baychester Ave - 5',\n",
    " 'BEACH 105 ST - AS': 'Beach 105th St - A-S',\n",
    " 'BEACH 25 ST - A': 'Beach 25th St - A',\n",
    " 'BEACH 36 ST - A': 'Beach 36th St - A',\n",
    " 'BEACH 44 ST - A': 'Beach 44th St - A',\n",
    " 'BEACH 60 ST - A': 'Beach 60th St - A',\n",
    " 'BEACH 67 ST - A': 'Beach 67th St - A',\n",
    " 'BEACH 90 ST - AS': 'Beach 90th St - A-S',\n",
    " 'BEACH 98 ST - AS': 'Beach 98th St - A-S',\n",
    " 'BEDFORD AV - L': 'Bedford Ave - L',\n",
    " 'BEDFORD PK BLVD - 4': 'Bedford Park Blvd - Lehman College - 4',\n",
    " 'BEDFORD PK BLVD - BD': 'Bedford Park Blvd - B-D',\n",
    " 'BEDFORD-NOSTRAN - G': 'Bedford - Nostrand Aves - G',\n",
    " 'BERGEN ST - 23': 'Bergen St - 2-3-4',\n",
    " 'BERGEN ST - FG': 'Bergen St - F-G',\n",
    " 'BEVERLEY ROAD - BQ': 'Beverly Rd - Q',\n",
    " 'BEVERLY RD - 25': 'Beverly Rd - 2-5',\n",
    " 'BLEECKER ST - 6DF': 'Bleecker St - 4-6-6 Express',\n",
    " 'BOROUGH HALL - 2345R': 'Borough Hall - 2-3',\n",
    " 'BOROUGH HALL - R2345': 'Borough Hall - 4-5',\n",
    " 'BOTANIC GARDEN - S2345': 'Botanic Garden - S',\n",
    " 'BOWERY - JZ': 'Bowery - J-Z',\n",
    " 'BOWLING GREEN - 45': 'Bowling Green - 4-5',\n",
    " 'BRIARWOOD - EF': 'Briarwood - Van Wyck Blvd - E-F',\n",
    " 'BRIGHTON BEACH - BQ': 'Brighton Beach - B-Q',\n",
    " 'BROAD CHANNEL - AS': 'Broad Channel - A-S',\n",
    " 'BROAD ST - JZ': 'Broad St - J-Z',\n",
    " 'BROADWAY - G': 'Broadway - G',\n",
    " 'BROADWAY JCT - ACJLZ': 'Broadway Junction - A-C',\n",
    " 'BRONX PARK EAST - 25': 'Bronx Park East - 2-5',\n",
    " 'BROOK AV - 6': 'Brook Ave - 6',\n",
    " 'BROOKLYN BRIDGE - 456JZ': 'Brooklyn Bridge - City Hall - 4-5-6-6 Express',\n",
    " 'BUHRE AV - 6': 'Buhre Ave - 6-6 Express',\n",
    " 'BURKE AV - 25': 'Burke Ave - 2-5',\n",
    " 'BURNSIDE AV - 4': 'Burnside Ave - 4',\n",
    " 'BUSHWICK AV - L': 'Bushwick - Aberdeen - L',\n",
    " 'CANAL ST - 1': 'Canal St - 1-2',\n",
    " 'CANAL ST - ACE': 'Canal St - Holland Tunnel - A-C-E',\n",
    " 'CANAL ST - JNQRZ6W': 'Canal St - 4-6-6 Express',\n",
    " 'CANARSIE-ROCKAW - L': 'Canarsie - Rockaway Pkwy - L',\n",
    " 'CARROLL ST - FG': 'Carroll St - F-G',\n",
    " 'CASTLE HILL AV - 6': 'Castle Hill Ave - 6-6 Express',\n",
    " 'CATHEDRAL PKWY - 1': 'Cathedral Pkwy (110th St) - 1',\n",
    " 'CATHEDRAL PKWY - BC': 'Cathedral Pkwy (110th St) - A-B-C',\n",
    " 'CENTRAL AV - M': 'Central Ave - M',\n",
    " 'CENTRAL PK N110 - 23': 'Central Park North (110th St) - 2-3',\n",
    " 'CHAMBERS ST - 123': 'Chambers St - 1-2-3',\n",
    " 'CHAMBERS ST - ACE23': 'Chambers St - A-C',\n",
    " 'CHAMBERS ST - JZ456': 'Chambers St - J-Z',\n",
    " 'CHAUNCEY ST - JZ': 'Chauncey St - J-Z',\n",
    " 'CHRISTOPHER ST - 1': 'Christopher St - Sheridan Sq - 1-2',\n",
    " 'CHURCH AV - 25': 'Church Ave - 2-5',\n",
    " 'CHURCH AV - BQ': 'Church Ave - B-Q',\n",
    " 'CHURCH AV - FG': 'Church Ave - F-G',\n",
    " 'CITY HALL - NRW': 'City Hall - R-W',\n",
    " 'CLARK ST - 23': 'Clark St - 2-3',\n",
    " 'CLASSON AV - G': 'Classon Ave - G',\n",
    " 'CLEVELAND ST - J': 'Cleveland St - J',\n",
    " 'CLINTON-WASH AV - C': 'Clinton - Washington Aves - A-C',\n",
    " 'CLINTON-WASH AV - G': 'Clinton - Washington Aves - G',\n",
    " 'CONEY IS-STILLW - DFNQ': 'Coney Island - Stillwell Av - D-F-N-Q',\n",
    " 'CORTELYOU RD - BQ': 'Cortelyou Rd - Q',\n",
    " 'CORTLANDT ST - 1': 'Cortlandt St - 1',\n",
    " 'CORTLANDT ST - RNW': 'Cortlandt St - R-W',\n",
    " 'COURT SQ - 7': 'Court Sq - 7-7 Express',\n",
    " 'COURT SQ - EMG': 'Long Island City - Court Sq - G',\n",
    " 'COURT SQ-23 ST - EMG': 'Court Sq - 23rd St - E-M',\n",
    " 'CRESCENT ST - JZ': 'Crescent St - J-Z',\n",
    " 'CROWN HTS-UTICA - 34': 'Crown Hts - Utica Ave - 3-4',\n",
    " 'CYPRESS AV - 6': 'Cypress Ave - 6',\n",
    " 'CYPRESS HILLS - J': 'Cypress Hills - J',\n",
    " 'DEKALB AV - BDNQR': 'DeKalb Ave - B-D-N-Q-R',\n",
    " 'DEKALB AV - L': 'DeKalb Ave - L',\n",
    " 'DELANCEY/ESSEX - FJMZ': 'Delancey St - Essex St - F',\n",
    " 'DITMAS AV - F': 'Ditmas Ave - F',\n",
    " 'DYCKMAN ST - 1': 'Dyckman St - 1',\n",
    " 'DYCKMAN ST - A': 'Dyckman St - A',\n",
    " \"E 143/ST MARY'S - 6\": \"E 143rd St - St Mary's St - 6\",\n",
    " 'E 149 ST - 6': 'E 149th St - 6',\n",
    " 'E 180 ST - 25': 'E 180th St - 2-5',\n",
    " 'EAST 105 ST - L': 'E 105th St - L',\n",
    " 'EAST BROADWAY - F': 'East Broadway - F',\n",
    " 'EASTCHSTER/DYRE - 5': 'Eastchester - Dyre Ave - 5',\n",
    " 'EASTN PKWY-MUSM - 23': 'Eastern Pkwy - Bklyn Museum - 2-3-4',\n",
    " 'ELDER AV - 6': 'Elder Ave - 6',\n",
    " 'ELMHURST AV - MR': 'Elmhurst Ave - E-M-R',\n",
    " 'EUCLID AV - AC': 'Euclid Ave - A-C-S',\n",
    " 'FAR ROCKAWAY - A': 'Far Rockaway - Mott Ave - A',\n",
    " 'FLATBUSH AV-B.C - 25': 'Brooklyn College - Flatbush Ave - 2-5',\n",
    " 'FLUSHING AV - G': 'Flushing Ave - G',\n",
    " 'FLUSHING AV - JM': 'Flushing Ave - J-M',\n",
    " 'FLUSHING-MAIN - 7': 'Flushing - Main St - 7-7 Express',\n",
    " 'FORDHAM RD - 4': 'Fordham Rd - 4',\n",
    " 'FORDHAM RD - BD': 'Fordham Rd - B-D',\n",
    " 'FOREST AVE - M': 'Forest Ave - M',\n",
    " 'FOREST HILLS 71 - EFMR': 'Forest Hills - 71st Av - E-F-M-R',\n",
    " 'FRANKLIN AV - 2345S': 'Franklin Ave - 2-3-4-5',\n",
    " 'FRANKLIN AV - ACS': 'Franklin Ave - A-C',\n",
    " 'FRANKLIN ST - 1': 'Franklin St - 1-2',\n",
    " 'FREEMAN ST - 25': 'Freeman St - 2-5',\n",
    " 'FRESH POND RD - M': 'Fresh Pond Rd - M',\n",
    " 'FT HAMILTON PKY - D': 'Ft Hamilton Pkwy - D',\n",
    " 'FT HAMILTON PKY - FG': 'Ft Hamilton Pkwy - F-G',\n",
    " 'FT HAMILTON PKY - N': 'Ft Hamilton Pkwy - N',\n",
    " 'FULTON ST - 2345ACJZ': 'Fulton St - 2-3',\n",
    " 'FULTON ST - ACJZ2345': 'Fulton St - 4-5',\n",
    " 'FULTON ST - G': 'Fulton St - G',\n",
    " 'GATES AV - JZ': 'Gates Ave - J-Z',\n",
    " 'GRAHAM AV - L': 'Graham Ave - L',\n",
    " 'GRAND ARMY PLAZ - 23': 'Grand Army Plaza - 2-3-4',\n",
    " 'GRAND ST - BD': 'Grand St - B-D',\n",
    " 'GRAND ST - L': 'Grand St - L',\n",
    " 'GRAND-NEWTOWN - MR': 'Grand Ave - Newtown - E-M-R',\n",
    " 'GRANT AV - A': 'Grant Ave - A-S',\n",
    " 'GREENPOINT AV - G': 'Greenpoint Ave - G',\n",
    " 'GRD CNTRL-42 ST - 4567S': 'Grand Central - 42nd St - 4-5-6-6 Express',\n",
    " 'GUN HILL RD - 25': 'Gun Hill Rd - 2-5',\n",
    " 'GUN HILL RD - 5': 'Gun Hill Rd - 5',\n",
    " 'HALSEY ST - J': 'Halsey St - J',\n",
    " 'HALSEY ST - L': 'Halsey St - L',\n",
    " 'HARLEM 148 ST - 3': 'Harlem - 148 St - 3',\n",
    " 'HEWES ST - JM': 'Hewes St - J-M',\n",
    " 'HIGH ST - AC': 'High St - A-C',\n",
    " 'HOUSTON ST - 1': 'Houston St - 1-2',\n",
    " 'HOWARD BCH JFK - A': 'Howard Beach - JFK Airport - A',\n",
    " 'HOYT ST - 23': 'Hoyt St - 2-3',\n",
    " 'HOYT-SCHER - ACG': 'Hoyt - Schermerhorn Sts - A-C-G',\n",
    " 'HUNTERS PT AV - 7': 'Hunters Point Ave - 7-7 Express',\n",
    " 'HUNTS POINT AV - 6': 'Hunts Point Ave - 6-6 Express',\n",
    " 'INTERVALE AV - 25': 'Intervale Ave - 2-5',\n",
    " 'INWOOD-207 ST - A': 'Inwood - 207th St - A',\n",
    " 'JACKSON AV - 25': 'Jackson Ave - 2-5',\n",
    " 'JAMAICA 179 ST - F': 'Jamaica - 179th St - F',\n",
    " 'JAMAICA CENTER - EJZ': 'Jamaica Ctr - Parsons / Archer - E-J-Z',\n",
    " 'JAMAICA VAN WK - E': 'Jamaica - Van Wyck - E',\n",
    " 'JAY ST-METROTEC - ACF': 'Jay St - MetroTech - A-C-F',\n",
    " 'JAY ST-METROTEC - R': 'Jay St - MetroTech - N-R',\n",
    " 'JEFFERSON ST - L': 'Jefferson St - L',\n",
    " 'JFK JAMAICA CT1 - E': 'Jamaica - Van Wyck - E',\n",
    " 'JKSN HT-ROOSVLT - EFMR7': 'Jackson Hts - Roosevelt Av - E-F-M-R',\n",
    " 'JUNCTION BLVD - 7': 'Junction Blvd - 7-7 Express',\n",
    " 'JUNIUS ST - 3': 'Junius St - 3-4',\n",
    " 'KEW GARDENS - EF': 'Kew Gardens - Union Tpke - E-F',\n",
    " 'KINGS HWY - BQ': 'Kings Hwy - B-Q',\n",
    " 'KINGS HWY - F': 'Kings Hwy - F',\n",
    " 'KINGS HWY - N': 'Kings Hwy - N',\n",
    " 'KINGSBRIDGE RD - 4': 'Kingsbridge Rd - 4',\n",
    " 'KINGSBRIDGE RD - BD': 'Kingsbridge Rd - B-D',\n",
    " 'KINGSTON AV - 3': 'Kingston Ave - 3-4',\n",
    " 'KINGSTON-THROOP - C': 'Kingston - Throop Aves - A-C',\n",
    " 'KNICKERBOCKER - M': 'Knickerbocker Ave - M',\n",
    " 'KOSCIUSZKO ST - J': 'Kosciuszko St - J',\n",
    " 'LAFAYETTE AV - C': 'Lafayette Ave - A-C',\n",
    " 'LEXINGTON AV/53 - EM6': 'Lexington Ave - 53rd St - E-M',\n",
    " 'LEXINGTON AV/63 - F': 'Lexington Ave - 63rd St - F-Q',\n",
    " 'LIBERTY AV - C': 'Liberty Ave - A-C',\n",
    " 'LIVONIA AV - L': 'Livonia Ave - L',\n",
    " 'LONGWOOD AV - 6': 'Longwood Ave - 6',\n",
    " 'LORIMER ST - JM': 'Lorimer St - J-M',\n",
    " 'LORIMER ST - LG': 'Lorimer St - L',\n",
    " 'MARBLE HILL-225 - 1': 'Marble Hill - 225th St - 1',\n",
    " 'MARCY AV - JMZ': 'Marcy Ave - J-M-Z',\n",
    " 'METROPOLITAN AV - GL': 'Metropolitan Ave - G',\n",
    " 'METROPOLITAN AV - M': 'Middle Village - Metropolitan Ave - M',\n",
    " 'METS-WILLETS PT - 7': 'Mets - Willets Point - 7-7 Express',\n",
    " 'MIDDLETOWN RD - 6': 'Middletown Rd - 6-6 Express',\n",
    " 'MONTROSE AV - L': 'Montrose Ave - L',\n",
    " 'MORGAN AV - L': 'Morgan Ave - L',\n",
    " 'MORISN AV/SNDVW - 6': 'Morrison Av - Soundview - 6',\n",
    " 'MORRIS PARK - 5': 'Morris Park - 5',\n",
    " 'MOSHOLU PKWY - 4': 'Mosholu Pkwy - 4',\n",
    " 'MT EDEN AV - 4': 'Mt Eden Ave - 4',\n",
    " 'MYRTLE AV - JMZ': 'Myrtle Ave - J-M-Z',\n",
    " 'MYRTLE-WILLOUGH - G': 'Myrtle-Willoughby Aves - G',\n",
    " 'MYRTLE-WYCKOFF - LM': 'Myrtle - Wyckoff Aves - L',\n",
    " 'NASSAU AV - G': 'Nassau Ave - G',\n",
    " 'NECK RD - BQ': 'Neck Rd - Q',\n",
    " 'NEPTUNE AV - F': 'Neptune Ave - F',\n",
    " 'NEREID AV - 25': 'Nereid Ave (238 St) - 2-5',\n",
    " 'NEVINS ST - 2345': 'Nevins St - 2-3-4-5',\n",
    " 'NEW LOTS - L': 'New Lots Ave - L',\n",
    " 'NEW LOTS AV - 3': 'New Lots Ave - 3-4',\n",
    " 'NEW UTRECHT AV - ND': 'New Utrecht Ave - N',\n",
    " 'NEWKIRK AV - 25': 'Newkirk Ave - 2-5',\n",
    " 'NEWKIRK PLAZA - BQ': 'Newkirk Ave - B-Q',\n",
    " 'NORTHERN BLVD - MR': 'Northern Blvd - E-M-R',\n",
    " 'NORWOOD 205 ST - D': 'Norwood - 205th St - D',\n",
    " 'NORWOOD AV - JZ': 'Norwood Ave - J-Z',\n",
    " 'NOSTRAND AV - 3': 'Nostrand Ave - 3-4',\n",
    " 'NOSTRAND AV - AC': 'Nostrand Ave - A-C',\n",
    " 'OCEAN PKWY - Q': 'Ocean Pkwy - Q',\n",
    " 'OZONE PK LEFFRT - A': 'Ozone Park - Lefferts Blvd - A-S',\n",
    " 'PARK PLACE - 23ACE': 'Park Pl - 2-3',\n",
    " 'PARK PLACE - S': 'Park Pl - S',\n",
    " 'PARKCHESTER - 6': 'Parkchester - 6-6 Express',\n",
    " 'PARKSIDE AV - BQ': 'Parkside Ave - Q',\n",
    " 'PARSONS BLVD - F': 'Parsons Blvd - F',\n",
    " 'PELHAM BAY PARK - 6': 'Pelham Bay Park - 6-6 Express',\n",
    " 'PELHAM PKWY - 25': 'Pelham Pkwy - 2-5',\n",
    " 'PELHAM PKWY - 5': 'Pelham Pkwy - 5',\n",
    " 'PENNSYLVANIA AV - 3': 'Pennsylvania Ave - 3-4',\n",
    " 'PRESIDENT ST - 25': 'President St - 2-5',\n",
    " 'PRINCE ST - NRW': 'Prince St - N-Q-R-W',\n",
    " 'PROSPECT AV - 25': 'Prospect Ave - 2-5',\n",
    " 'PROSPECT AV - R': 'Prospect Ave - D-N-R',\n",
    " 'PROSPECT PARK - BQS': 'Prospect Park - B-Q-S',\n",
    " 'QUEENS PLAZA - EMR': 'Queens Plz - E-M-R',\n",
    " 'QUEENSBORO PLZ - 7NQW': 'Queensboro Plz - 7-7 Express-N-W',\n",
    " 'RALPH AV - C': 'Ralph Ave - A-C',\n",
    " 'RECTOR ST - 1': 'Rector St - 1',\n",
    " 'RECTOR ST - NRW': 'Rector St - R-W',\n",
    " 'RIT-ROOSEVELT - R': 'Jackson Hts - Roosevelt Av - E-F-M-R',\n",
    " 'ROCKAWAY AV - 3': 'Rockaway Ave - 3-4',\n",
    " 'ROCKAWAY AV - C': 'Rockaway Ave - A-C',\n",
    " 'ROCKAWAY BLVD - A': 'Rockaway Blvd - A-S',\n",
    " 'ROCKAWAY PARK B - AS': 'Rockaway Park - Beach 116 St - A-S',\n",
    " 'ROOSEVELT ISLND - F': 'Roosevelt Island - Main St - F',\n",
    " 'SARATOGA AV - 3': 'Saratoga Ave - 3-4',\n",
    " 'SENECA AVE - M': 'Seneca Ave - M',\n",
    " 'SHEEPSHEAD BAY - BQ': 'Sheepshead Bay - B-Q',\n",
    " 'SHEPHERD AV - C': 'Shepherd Ave - A-C',\n",
    " 'SIMPSON ST - 25': 'Simpson St - 2-5',\n",
    " 'SMITH-9 ST - FG': 'Smith - 9th Sts - F-G',\n",
    " 'SOUTH FERRY - 1RW': 'South Ferry - 1',\n",
    " 'SPRING ST - 6': 'Spring St - 4-6-6 Express',\n",
    " 'SPRING ST - CE': 'Spring St - A-C-E',\n",
    " 'ST LAWRENCE AV - 6': 'St Lawrence Ave - 6',\n",
    " 'STEINWAY ST - MR': 'Steinway St - E-M-R',\n",
    " 'STERLING ST - 25': 'Sterling St - 2-5',\n",
    " 'SUTPHIN BLVD - F': 'Sutphin Blvd - F',\n",
    " 'SUTPHIN-ARCHER - EJZ': 'Sutphin Blvd - Archer Av - E-J-Z',\n",
    " 'SUTTER AV - L': 'Sutter Ave - L',\n",
    " 'SUTTER AV-RUTLD - 3': 'Sutter Ave - Rutland Road - 3-4',\n",
    " 'TIMES SQ-42 ST - 1237ACENQRS': 'Times Sq - 42nd St - 1-2-3',\n",
    " 'TIMES SQ-42 ST - 1237ACENQRSW': 'Times Sq - 42nd St - 7-7 Express',\n",
    " 'TIMES SQ-42 ST - ACENQRS1237W': 'Times Sq - 42nd St - N-Q-R-W',\n",
    " 'TREMONT AV - BD': 'Tremont Ave - B-D',\n",
    " 'TWENTY THIRD ST - 1': '23rd St - 1-2',\n",
    " 'UNION ST - R': 'Union St - D-N-R',\n",
    " 'UTICA AV - AC': 'Utica Ave - A-C',\n",
    " 'V.CORTLANDT PK - 1': 'Van Cortlandt Park - 242nd St - 1',\n",
    " 'VAN SICLEN AV - 3': 'Van Siclen Ave - 3-4',\n",
    " 'VAN SICLEN AV - JZ': 'Van Siclen Ave - J-Z',\n",
    " 'VAN SICLEN AVE - C': 'Van Siclen Ave - A-C',\n",
    " 'VERNON-JACKSON - 7': 'Vernon Blvd - Jackson Ave - 7-7 Express',\n",
    " 'W 4 ST-WASH SQ - ABCDEFM': 'W 4th St - Washington Sq (Lower) - B-D-F-M',\n",
    " 'W 8 ST-AQUARIUM - FQ': 'W 8th St - NY Aquarium - F-Q',\n",
    " 'WAKEFIELD/241 - 2': 'Wakefield - 241st St - 2',\n",
    " 'WALL ST - 23': 'Wall St - 2-3',\n",
    " 'WALL ST - 45': 'Wall St - 4-5',\n",
    " 'WEST FARMS SQ - 25': 'West Farms Sq - E Tremont Av - 2-5',\n",
    " 'WESTCHESTER SQ - 6': 'Westchester Sq - E Tremont Ave - 6-6 Express',\n",
    " 'WHITEHALL S-FRY - R1W': 'Whitehall St - R-W',\n",
    " 'WHITLOCK AV - 6': 'Whitlock Ave - 6',\n",
    " 'WILSON AV - L': 'Wilson Ave - L',\n",
    " 'WINTHROP ST - 25': 'Winthrop St - 2-5',\n",
    " 'WOODHAVEN BLVD - JZ': 'Woodhaven Blvd - J-Z',\n",
    " 'WOODHAVEN BLVD - MR': 'Woodhaven Blvd - Queens Mall - E-M-R',\n",
    " 'WOODLAWN - 4': 'Woodlawn - 4',\n",
    " 'WORLD TRADE CTR - ACE23': 'World Trade Center - E',\n",
    " 'YORK ST - F': 'York St - F',\n",
    " 'ZEREGA AV - 6': 'Zerega Ave - 6-6 Express',\n",
    " 'ORCHARD BEACH - 6': '',\n",
    " 'NEWARK HW BMEBE - 1': '',\n",
    " 'HARRISON - 1': '',\n",
    " 'JOURNAL SQUARE - 1': '',\n",
    " 'GROVE STREET - 1': '',\n",
    " 'EXCHANGE PLACE - 1': '',\n",
    " 'PAVONIA/NEWPORT - 1': '',\n",
    " 'CITY / BUS - 1': '',\n",
    " '9TH STREET - 1': '',\n",
    " 'THIRTY ST - 1': '',\n",
    " 'LACKAWANNA - 1': '',\n",
    " 'THIRTY THIRD ST - 1': '',\n",
    " 'NEWARK BM BW - 1': '',\n",
    " 'NEWARK C - 1': '',\n",
    " 'NEWARK HM HE - 1': '',\n",
    " 'PATH WTC 2 - 1': '',\n",
    " 'PATH NEW WTC - 1': '',\n",
    " 'ST. GEORGE - 1': '',\n",
    " 'TOMPKINSVILLE - 1': ''}\n",
    "stationmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"%s all done!\" % (strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
